{"meta":{"title":"Hui Yu","subtitle":null,"description":null,"author":"Hui Yu","url":"ityuhui.github.io","root":"/"},"pages":[{"title":"","date":"2020-06-13T12:48:12.894Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"404.html","permalink":"ityuhui.github.io/404.html","excerpt":"","text":"404"},{"title":"about me","date":"2020-01-01T02:26:36.000Z","updated":"2020-09-19T04:36:07.340Z","comments":true,"path":"about/index.html","permalink":"ityuhui.github.io/about/index.html","excerpt":"","text":"于辉，软件工程师，关注分布式计算。 欢迎关注微信公众号：分布式计算小记"},{"title":"categories","date":"2020-01-01T02:20:44.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"categories/index.html","permalink":"ityuhui.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-01-01T02:23:34.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"tags/index.html","permalink":"ityuhui.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"K3S 实验总结","slug":"k3s-experiment","date":"2020-11-13T14:21:15.000Z","updated":"2020-11-13T14:27:03.101Z","comments":true,"path":"2020/11/13/k3s-experiment/","link":"","permalink":"ityuhui.github.io/2020/11/13/k3s-experiment/","excerpt":"","text":"介绍k3s是rancher公司发布的kubernetes分发版，用于物联网、边缘计算，所以对kubernetes进行了很多剪裁。 导入镜像在具有docker的机器上 12docker save -o busybox.tar busyboxaaascp busybox.tar ubuntu@k3s_machine:~/ 在k3s_machine上 1ctr image import busybox.tar","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/categories/kubernetes/"}],"tags":[{"name":"k3s","slug":"k3s","permalink":"ityuhui.github.io/tags/k3s/"}]},{"title":"Reactjs 学习笔记","slug":"reactjs-learning-notes","date":"2020-10-06T13:48:17.000Z","updated":"2020-10-07T06:13:59.565Z","comments":true,"path":"2020/10/06/reactjs-learning-notes/","link":"","permalink":"ityuhui.github.io/2020/10/06/reactjs-learning-notes/","excerpt":"预备知识：JavaScript新特性 let,const 定义常量 class 箭头表达式 1x =&gt; x*x 的意思是 123function(x) &#123; return x*x&#125; 箭头表达式没有this","text":"预备知识：JavaScript新特性 let,const 定义常量 class 箭头表达式 1x =&gt; x*x 的意思是 123function(x) &#123; return x*x&#125; 箭头表达式没有this JSX 大括号{}内是JavaScript表达式 JSX本身也是JavaScript表达式，可以作为参数传入JS函数，也可以作为JS的返回值。 组件函数组件定义组件最简单的方式就是编写 JavaScript 函数： 123function Welcome(props) &#123; return &lt;h1&gt;Hello, &#123;props.name&#125;&lt;/h1&gt;;&#125; 该函数是一个有效的 React 组件，因为它接收唯一带有数据的 “props”（代表属性）对象与并返回一个 React 元素。这类组件被称为“函数组件”，因为它本质上就是 JavaScript 函数。 类组件12345class Welcome extends React.Component &#123; render() &#123; return &lt;h1&gt;Hello, &#123;this.props.name&#125;&lt;/h1&gt;; &#125;&#125; 上述两个组件在 React 里是等效的。","categories":[{"name":"前端开发","slug":"前端开发","permalink":"ityuhui.github.io/categories/前端开发/"}],"tags":[{"name":"react","slug":"react","permalink":"ityuhui.github.io/tags/react/"}]},{"title":"Mongodb Redis etcd","slug":"mongodb-redis-etcd","date":"2020-10-04T02:58:07.000Z","updated":"2020-10-04T03:00:10.013Z","comments":true,"path":"2020/10/04/mongodb-redis-etcd/","link":"","permalink":"ityuhui.github.io/2020/10/04/mongodb-redis-etcd/","excerpt":"","text":"MongoDB文档（对象）数据库 MongoDB却是一个“存储数据”的系统，增删改查可以添加很多条件，就像SQL数据库一样灵活 redis键值对 Redis主要把数据存储在内存中，其“缓存”的性质远大于其“数据存储“的性质，其中数据的增删改查也只是像变量操作一样简单； etcd","categories":[{"name":"数据库","slug":"数据库","permalink":"ityuhui.github.io/categories/数据库/"}],"tags":[{"name":"database","slug":"database","permalink":"ityuhui.github.io/tags/database/"},{"name":"mongodb","slug":"mongodb","permalink":"ityuhui.github.io/tags/mongodb/"},{"name":"redis","slug":"redis","permalink":"ityuhui.github.io/tags/redis/"},{"name":"etcd","slug":"etcd","permalink":"ityuhui.github.io/tags/etcd/"}]},{"title":"进程间通信","slug":"interproces-communication","date":"2020-10-01T12:16:17.000Z","updated":"2020-10-01T12:21:31.896Z","comments":true,"path":"2020/10/01/interproces-communication/","link":"","permalink":"ityuhui.github.io/2020/10/01/interproces-communication/","excerpt":"","text":"在操作系统原理里，进程间通讯有几种方法： 信号 管道 共享内存 消息队列 socket 在软件开发中，常用最后一种方法，就是通过网络，但是网络又有几种方法： REST SOAP Message Queue gPRC 自己实现socket server,socket client,自己定义消息","categories":[{"name":"软件开发的基础知识","slug":"软件开发的基础知识","permalink":"ityuhui.github.io/categories/软件开发的基础知识/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"ityuhui.github.io/tags/操作系统/"},{"name":"进程间通信","slug":"进程间通信","permalink":"ityuhui.github.io/tags/进程间通信/"},{"name":"interprocess communication","slug":"interprocess-communication","permalink":"ityuhui.github.io/tags/interprocess-communication/"}]},{"title":"Solidity的一些总结","slug":"solidity-summary","date":"2020-09-13T09:03:50.000Z","updated":"2020-09-19T03:51:14.044Z","comments":true,"path":"2020/09/13/solidity-summary/","link":"","permalink":"ityuhui.github.io/2020/09/13/solidity-summary/","excerpt":"介绍solidity是etherum上的智能合约编程语言，其语义类似于Javascript、C++、Python，由C++开发","text":"介绍solidity是etherum上的智能合约编程语言，其语义类似于Javascript、C++、Python，由C++开发 IDE最好的solidity IDE是Remix，这是一个网页版的IDE。 文档https://solidity.readthedocs.io/","categories":[{"name":"区块链","slug":"区块链","permalink":"ityuhui.github.io/categories/区块链/"}],"tags":[{"name":"block chain","slug":"block-chain","permalink":"ityuhui.github.io/tags/block-chain/"},{"name":"ethereum","slug":"ethereum","permalink":"ityuhui.github.io/tags/ethereum/"},{"name":"solidity","slug":"solidity","permalink":"ityuhui.github.io/tags/solidity/"}]},{"title":"Kubernetes OIDC 鉴权","slug":"kubernetes-oidc","date":"2020-08-06T11:15:14.000Z","updated":"2020-08-06T11:20:32.383Z","comments":true,"path":"2020/08/06/kubernetes-oidc/","link":"","permalink":"ityuhui.github.io/2020/08/06/kubernetes-oidc/","excerpt":"","text":"介绍Kubernetes本身不提供用户管理，所以，Keycloak可以做用户管理和客户端管理。 Keycloak 配置创建客户端进入管理界面 1http://localhost:8080 进入前一篇文章Keycloak创建的Realm kubernetes界面","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/categories/kubernetes/"}],"tags":[{"name":"Keycloak","slug":"Keycloak","permalink":"ityuhui.github.io/tags/Keycloak/"},{"name":"oidc","slug":"oidc","permalink":"ityuhui.github.io/tags/oidc/"}]},{"title":"Keycloak","slug":"Keycloak-Introduction","date":"2020-08-05T14:40:53.000Z","updated":"2020-08-06T11:21:03.784Z","comments":true,"path":"2020/08/05/Keycloak-Introduction/","link":"","permalink":"ityuhui.github.io/2020/08/05/Keycloak-Introduction/","excerpt":"介绍KeyCloak是Redhat开发的SSO服务程序。可以提供OpenID Connect服务。 安装从官网下载压缩包，解压缩 运行1bin/standalone.sh","text":"介绍KeyCloak是Redhat开发的SSO服务程序。可以提供OpenID Connect服务。 安装从官网下载压缩包，解压缩 运行1bin/standalone.sh 配置只能在本机访问GUI，不能通过网络远程访问 登录1http://localhost:8080 创建管理员账户和密码创建realm取名Kubernetes 配置SSL访问创建CA和证书使用openssl工具，创建自签名的根证书和证书 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bashmkdir -p sslcat &lt;&lt; EOF &gt; ssl/ca.cnf[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name][ v3_req ]basicConstraints = CA:TRUEEOFcat &lt;&lt; EOF &gt; ssl/req.cnf[req]req_extensions = v3_reqdistinguished_name = req_distinguished_name[req_distinguished_name][ v3_req ]basicConstraints = CA:FALSEkeyUsage = nonRepudiation, digitalSignature, keyEnciphermentsubjectAltName = @alt_names[alt_names]IP.1 = 1.2.3.4EOFopenssl genrsa -out ssl/ca-key.pem 2048openssl req -x509 -new -nodes -key ssl/ca-key.pem -days 365 -out ssl/ca.pem -subj \"//CN=keycloak-ca\" -extensions v3_req -config ssl/ca.cnfopenssl genrsa -out ssl/keycloak.pem 2048openssl req -new -key ssl/keycloak.pem -out ssl/keycloak-csr.pem -subj \"//CN=keycloak\" -config ssl/req.cnfopenssl x509 -req -in ssl/keycloak-csr.pem -CA ssl/ca.pem -CAkey ssl/ca-key.pem -CAcreateserial -out ssl/keycloak.crt -days 365 -extensions v3_req -extfile ssl/req.cnf 生成keystore因为Keycloak是Java开发的，所以只能接受Java keystore (jks)的密钥对。 123openssl pkcs12 -export -out keycloak.p12 -inkey keycloak.pem -in keycloak.crt -certfile ca.pemkeytool -importkeystore -deststorepass 'passw0rd' -destkeystore keycloak.jks -srckeystore keycloak.p12 -srcstoretype PKCS12 配置Keycloak使用SSL把上一步生成的kaycloak.jks放到keycloak\\standalone\\configuration目录下 使用Keycloak CLI: 123456789101112131415161718192021222324bin\\jboss-cli.bat[disconnected /] connect[standalone@localhost:9990 /] /core-service=management/security-realm=UndertowRealm:add()&#123;\"outcome\" =&gt; \"success\"&#125;[standalone@localhost:9990 /] /core-service=management/security-realm=UndertowRealm/server-identity=ssl:add(keystore-path=keycloak.jks, keystore-relative-to=jboss.server.config.dir, keystore-password=passw0rd)&#123; \"outcome\" =&gt; \"success\", \"response-headers\" =&gt; &#123; \"operation-requires-reload\" =&gt; true, \"process-state\" =&gt; \"reload-required\" &#125;&#125;[standalone@localhost:9990 /] /subsystem=undertow/server=default-server/https-listener=https:write-attribute(name=security-realm, value=UndertowRealm)&#123; \"outcome\" =&gt; \"success\", \"response-headers\" =&gt; &#123; \"operation-requires-reload\" =&gt; true, \"process-state\" =&gt; \"reload-required\" &#125;&#125; 重新启动 Keycloak访问https://ip:8443 可以看到关于https证书的警告。代表配置成功。 接下来，就可以配置Keycloak给kubernetes提供OIDC认证服务了。 参考文献Keycloak Documentation 为 Kubernetes 搭建支持 OpenId Connect 的身份认证系统","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/categories/kubernetes/"}],"tags":[{"name":"Keycloak","slug":"Keycloak","permalink":"ityuhui.github.io/tags/Keycloak/"},{"name":"oidc","slug":"oidc","permalink":"ityuhui.github.io/tags/oidc/"}]},{"title":"git merge 操作","slug":"git-merge-upstream","date":"2020-06-23T11:33:28.000Z","updated":"2020-10-31T11:52:14.162Z","comments":true,"path":"2020/06/23/git-merge-upstream/","link":"","permalink":"ityuhui.github.io/2020/06/23/git-merge-upstream/","excerpt":"git merge upstream12345678git remote add upstream https://github.com/OpenAPITools/openapi-generatorgit fetch upstreamgit checkout mastergit merge upstream/mastergit push origin master","text":"git merge upstream12345678git remote add upstream https://github.com/OpenAPITools/openapi-generatorgit fetch upstreamgit checkout mastergit merge upstream/mastergit push origin master git branch merge1234567891011121314git branch -a #先查看下当前的本地和远程分支git checkout -b my_dev origin/dev #或者是切换到本地的my_dev分支，假如已经存在的话，即git checkout my_dev git pull #将本地分支my_dev对应的远程分支dev拉下来git checkout master #切换到master分支git pull #确保master分支也是最新的git merge my_dev #执行合并的关键代码，此时执行结果时将本地的my_dev合并到本地master分支git push origin master #将合并的本地master分支推送到远程master 删除分支删除本地分支1git branch -d &lt;BranchName&gt; 删除远程分支1git push origin --delete &lt;BranchName&gt; 查看本地分支的追踪情况1git remote show origin 删除已经被远程删除的分支1git remote prune origin 拉取远程存在，但是本地没有的分支123git pullgit checkout -b abranch origin/abranch 解决冲突解决冲突有两种方法，merge和rebase rebase在开发分支上，执行 1git rebase master 解决冲突执行 123git add .git rebase --continuegit commit merge我自己只用rebase 代码回滚方式一，使用revert会产生新的提交记录 12git revert HEADgit push origin master 方式二，使用reset不会产生新的提交记录 12git reset --hard HEAD^git push origin master -f","categories":[{"name":"git的使用","slug":"git的使用","permalink":"ityuhui.github.io/categories/git的使用/"}],"tags":[{"name":"git","slug":"git","permalink":"ityuhui.github.io/tags/git/"}]},{"title":"Python virtualenv requirements pytest jupyter","slug":"python-virtualenv-requirements-pytest-jupyter","date":"2020-06-22T13:50:50.000Z","updated":"2020-06-22T13:52:42.699Z","comments":true,"path":"2020/06/22/python-virtualenv-requirements-pytest-jupyter/","link":"","permalink":"ityuhui.github.io/2020/06/22/python-virtualenv-requirements-pytest-jupyter/","excerpt":"Python 虚拟环境介绍Python虚拟环境可以搭建一个当前工作的包依赖系统，所有的依赖包都下载到当前目录下，不会对系统的Python环境造成影响。 虚拟环境指的是多个依赖包环境共存，并不是多个python共存。所有的虚拟环境都使用一个python。","text":"Python 虚拟环境介绍Python虚拟环境可以搭建一个当前工作的包依赖系统，所有的依赖包都下载到当前目录下，不会对系统的Python环境造成影响。 虚拟环境指的是多个依赖包环境共存，并不是多个python共存。所有的虚拟环境都使用一个python。 安装 virtualenv12virtualenv --version #查看是否已经安装pip install virtualenv 在当前的项目目录下生成虚拟环境1virtualenv $&#123;virtual_env_name&#125; 激活虚拟环境1$&#123;virtual_env_name&#125;/script/activate 退出虚拟环境1$&#123;virtual_env_name&#125;/script/deactivate Python 包依赖生成requirements.txt文件1pip freeze &gt; requirements.txt 安装requirements.txt依赖1pip install -r requirements.txt pytest安装12pip install pytestpy.test --version 编写test case将文件命令为以 test_ 开头 12345def func(x): return x+1def test_func(): assert func(3) == 4 运行1py.test jupyter notebook安装1pip install notebook 运行1jupyter notebook 配置远程可访问生成配置文件1jupyter notebook --generate-config 修改配置文件1c.NotebookApp.ip=&apos;*&apos; #×允许任何ip访问 Matplotlibpython的绘图库，与Numpy一起使用，是MatLab的开源替代方案","categories":[{"name":"Python","slug":"Python","permalink":"ityuhui.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"ityuhui.github.io/tags/python/"},{"name":"virtualenv","slug":"virtualenv","permalink":"ityuhui.github.io/tags/virtualenv/"},{"name":"requirements","slug":"requirements","permalink":"ityuhui.github.io/tags/requirements/"},{"name":"pytest","slug":"pytest","permalink":"ityuhui.github.io/tags/pytest/"},{"name":"jupyter","slug":"jupyter","permalink":"ityuhui.github.io/tags/jupyter/"}]},{"title":"Introduction to Apache Spark","slug":"Spark-Introduction","date":"2020-06-21T02:59:22.000Z","updated":"2020-06-21T03:01:42.194Z","comments":true,"path":"2020/06/21/Spark-Introduction/","link":"","permalink":"ityuhui.github.io/2020/06/21/Spark-Introduction/","excerpt":"1 IntroductionApache spark is a batch computing framework. It is used to replace MapReduce in Hadoop. It can be deployed on Apache Yarn or Mesos, Kubernetes.","text":"1 IntroductionApache spark is a batch computing framework. It is used to replace MapReduce in Hadoop. It can be deployed on Apache Yarn or Mesos, Kubernetes. 1.1 Compare1.1.1 FlinkFlink is a stream computing framework. It is used for millisecond-level computing 2 Use Case2.1 Interactive anylysis with the Spark shell2.2 Self-contain applications written with Spark API3 Programming Guides3.1 RDDCore and old API 3.2 Spark SQL, Datasets, DataFramesTerm. Dataset is the new interface added in Spark1.6 DataFrame is a Dataset organized into named columns. It is equivalent to a table in a relational database. Getting Started Create SparkSession Create DataFrames 3.3 Structured StreamingUsing Datasets and DataFrame, newer API than DStreams 3.4 Spark Streaming using DStreamsUsing DStreams, old stream API 3.5 MLlibmaching learning algorithms 3.6 GraphXgraphs computing","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"Spark","slug":"Spark","permalink":"ityuhui.github.io/tags/Spark/"}]},{"title":"Dominant Resource Fairness算法","slug":"DRF","date":"2020-06-20T13:36:36.000Z","updated":"2020-06-30T13:09:52.937Z","comments":true,"path":"2020/06/20/DRF/","link":"","permalink":"ityuhui.github.io/2020/06/20/DRF/","excerpt":"","text":"1. 介绍DRF算法是用于资源调度的算法，被yarn和mesos的调度器所采用。 2. 动机基于slot的算法，不是没有用尽资源，就是过度使用资源。 3. 分配的属性为了可以评估一个算法是否公平，论文提出了四个属性，以此来指导算法的开发。 Sharing incentive每一个用户应该更好的分享集群里的资源，而不是排他性使用他所有的那一部分。假设一个集群里有相同的机器和n个用户，每个用户都不可能在一个1/n资源分区里分配更多的任务。 Strategy-proofness用户不可能通过撒谎的方式，获得更多的资源。 Envy-freeness一个用户不能获的另外一个用户的分配资源。 Pareto efficiency如果一个用户没有降低他的分配，那么其他用户不可能提高分配。 4. DRF算法DRF算法满足前一章所提出的四个属性。对于每一个用户，DRF计算出给该用户分配的每一个资源的份额。一个用户的所有的资源份额中，数量最大的，被称之为该用户的“主导份额”，该资源被称之该用户的“主导资源”。不同的用户可能有不同的主导资源。 4.1 例子假设一个系统，有9 CPU，18GB 内存。两个用户，A运行任务（1 CPU，4 GB），B运行任务(3 CPU, 1 GB)。 用户A的每个task消耗1/9的总CPU，2/9的总内存，所以A的主导资源是内存。 用户B的每个task消耗1/3的总CPU，1/18的总内存，所以B的主导资源是CPU。 DRF算法会让所有用户的主导份额保持相等：A执行3个Task, 共消耗（3 CPU， 12 GB）B执行2个Task，共消耗（6 CPU， 2 GB）在这个分配下，每个用户都获得了相等的主导份额：A得到了2/3的总内存，B得到了2/3的总CPU 这一分配可以使用数学计算来表达，设x是A的task数，y是B的task数，那么，A收到（x CPU,4x GB）, B得到（3y CPU , y GB）, 总的资源分配是（x+3y CPU, 4x+y GB）, 让A的主导份额 4x/18 等于B的主导份额 3y/9, 那么，DRF的计算如下： max(x,y)需要满足： 123x + 3y &lt;= 94x + y &lt;= 182x / 9 = y / 3 解答这个问题可得 12x = 3y = 2 因此,A得到（3 CPU，12 GB），B得到（6 CPU，2 GB） 注意，DRF并不需要让用户的主导份额总是相等。当一个用户的总需求已经得到满足，该用户就不会在需要新的task，因此超过的资源会被其他用户分配，就像max-min fairness一样，除此之外，如果一个资源已经耗尽，不需要该资源的用户可以继续得到更高份额的其他资源。 4.2 DRF 调度算法4.1说的是最终的分配结果，并没有给出具体的每一步的算法，下面来详细说明算法： 在每一步，DRF挑出主导份额最小的用户，（刚开始都是0，所以随便选一个），如果有足够的资源可以启动一个task,那么就分配资源给该用户，启动Task, 直到系统里没有资源可用。 假设第一步挑出了B，那么B的份额变成了（3/9， 1/18），B的主导份额是1/3，这个时候A的主导份额是0，开始调度A。 A得到（1/9，4/18），A的主导份额变成了2/9，还是比B的主导份额小，所以接下来还是调度A。 A变成（2/9，8/18），A的主导份额变成了4/9，大于B的主导份额1/3，所以接下来调度B。 一直到最后，A和B的主导份额都变成了2/3，这个时候集群里的CPU分配完了，调度无法继续，调度结束。 在这个例子里，分配停止是因为资源用光了。但是，一般情况下，当某个资源用光了以后，分配可能还会继续，因为有些task根本不需要这种被用光的资源。 上述算法可以使用二叉堆来存储每一个用户的主导份额，每一次对n的用户的调度的时间复杂度是O(log n) 4.3 加权的DRF在实际应用中，很多时候用户得到的资源并不应该是相等的，例如，执行重要的任务的用户应该得到更多的资源。因此，我们提出了加权DRF。 在这一算法里，每一个用户i都被关联一个加权向量Wi = (wi1,…,wim), wij代表用户i对于资源j的权重，这个时候，用户i的主导份额变成 maxj{ uij / wij}, uij是用户i","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"资源调度","slug":"资源调度","permalink":"ityuhui.github.io/tags/资源调度/"},{"name":"DRF","slug":"DRF","permalink":"ityuhui.github.io/tags/DRF/"}]},{"title":"raft算法","slug":"raft-introduction","date":"2020-06-20T00:52:55.000Z","updated":"2020-06-20T00:56:16.972Z","comments":true,"path":"2020/06/20/raft-introduction/","link":"","permalink":"ityuhui.github.io/2020/06/20/raft-introduction/","excerpt":"介绍当一个集群里的每台机器上都有一套自己的数据，让所有机器上的数据都保证一致的算法，就叫做分布式数据一致性算法。 最知名的分布式一致性算法是paxos，但是它非常难懂，并且由于论文并没有将其算法的细节描述清楚，导致了不同的工程实现。 Raft是另外一个知名的分布式数据一致性算法，由于采用了“强领导人”机制，使其较paxos简单，再加上论文比较详细的描述了算法的细节，使得其在工程上容易实现，所以目前生产环境上应用最广泛，例如etcd。","text":"介绍当一个集群里的每台机器上都有一套自己的数据，让所有机器上的数据都保证一致的算法，就叫做分布式数据一致性算法。 最知名的分布式一致性算法是paxos，但是它非常难懂，并且由于论文并没有将其算法的细节描述清楚，导致了不同的工程实现。 Raft是另外一个知名的分布式数据一致性算法，由于采用了“强领导人”机制，使其较paxos简单，再加上论文比较详细的描述了算法的细节，使得其在工程上容易实现，所以目前生产环境上应用最广泛，例如etcd。 算法的组成选举节点有三种状态 follower candidate leader 当节点启动的时候，进入follower状态，接收来自leader的心跳消息。当节点在一段时间后没有收到心跳消息，则认为leader死亡，就自行进入candidate状态，发起选举。向集群里的其他节点发送消息。当收到多数节点的同意消息之后，该节点由candidate状态进入leader状态，向集群里的其他follower发送心跳。 日志复制安全参考Raft论文中文翻译","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"raft","slug":"raft","permalink":"ityuhui.github.io/tags/raft/"},{"name":"分布式一致性","slug":"分布式一致性","permalink":"ityuhui.github.io/tags/分布式一致性/"}]},{"title":"GraphQL介绍","slug":"GraphQL-introduction","date":"2020-06-17T12:54:49.000Z","updated":"2020-06-17T13:01:03.714Z","comments":true,"path":"2020/06/17/GraphQL-introduction/","link":"","permalink":"ityuhui.github.io/2020/06/17/GraphQL-introduction/","excerpt":"什么是GraphQLGraphQL 一种用于API的查询语言，具有优于RESTful的特点。它可以只用一个请求获取多个资源。","text":"什么是GraphQLGraphQL 一种用于API的查询语言，具有优于RESTful的特点。它可以只用一个请求获取多个资源。 举例Request 1234567&#123; hero &#123; name height mass &#125;&#125; Response 123456&#123; &quot;hero&quot;:&#123; &quot;name&quot;: &quot;Luke Skywalker&quot;, &quot;height&quot; : 77 &#125;&#125;","categories":[{"name":"Web开发","slug":"Web开发","permalink":"ityuhui.github.io/categories/Web开发/"}],"tags":[{"name":"web","slug":"web","permalink":"ityuhui.github.io/tags/web/"},{"name":"GraphQL","slug":"GraphQL","permalink":"ityuhui.github.io/tags/GraphQL/"},{"name":"REST","slug":"REST","permalink":"ityuhui.github.io/tags/REST/"}]},{"title":"现代C++","slug":"modern-c-plus-plus","date":"2020-06-16T13:15:40.000Z","updated":"2020-06-17T13:04:28.041Z","comments":true,"path":"2020/06/16/modern-c-plus-plus/","link":"","permalink":"ityuhui.github.io/2020/06/16/modern-c-plus-plus/","excerpt":"Move语义智能指针的推荐用法1.不要再使用new, delete, 一律用make_shared,make_unique代替 2.只有具有ownership的关系，才用智能指针，否则使用 T &amp;, 或者 T *","text":"Move语义智能指针的推荐用法1.不要再使用new, delete, 一律用make_shared,make_unique代替 2.只有具有ownership的关系，才用智能指针，否则使用 T &amp;, 或者 T * 新的数据类型std::any类似于void * std::variant类似于c语言里的union Lamda多线程库","categories":[{"name":"C++","slug":"C","permalink":"ityuhui.github.io/categories/C/"}],"tags":[{"name":"C-plus-plus","slug":"C-plus-plus","permalink":"ityuhui.github.io/tags/C-plus-plus/"},{"name":"C++","slug":"C","permalink":"ityuhui.github.io/tags/C/"},{"name":"Modern C++","slug":"Modern-C","permalink":"ityuhui.github.io/tags/Modern-C/"},{"name":"C++17","slug":"C-17","permalink":"ityuhui.github.io/tags/C-17/"}]},{"title":"在Azure云上使用HPC Services for Excel运行Excel运算","slug":"Workbook-offload-to-Azure","date":"2020-06-13T13:29:22.000Z","updated":"2020-06-13T13:46:45.948Z","comments":true,"path":"2020/06/13/Workbook-offload-to-Azure/","link":"","permalink":"ityuhui.github.io/2020/06/13/Workbook-offload-to-Azure/","excerpt":"前提条件你需要安装最低Windows HPC server 2012 SP1 在你的桌面机（你用来做Excel运算的机器）上，你需要安装Excel 2010和HPC client utilities. 你还需要部署一些Azure虚拟机节点，安装有Excel,用于实际运算。","text":"前提条件你需要安装最低Windows HPC server 2012 SP1 在你的桌面机（你用来做Excel运算的机器）上，你需要安装Excel 2010和HPC client utilities. 你还需要部署一些Azure虚拟机节点，安装有Excel,用于实际运算。 例子ExcelService配置在运行ExcelService之前，我们需要现在ZzureNode上部署excel service 打包依赖文件 将这些文件上传到云存储里 同步到Azure节点上 例子1：在云上使用一个静态的workbook步骤1.创建包 1&gt; hpcpack create ConvertiblePricing_AzureCloud_Static.zip ConvertiblePricing_AzureCloud_Static.xlsb 2.上传包 1&gt; hpcpack upload ConvertiblePricing_AzureCloud_Static.zip /scheduler:HEADNODE /nodetemplate:\"Default AzureNode Template\" 3.同步到Azure节点上 1&gt; clusrun /scheduler:HEADNODE /template:AzureTemplate hpcsync 4.配置 打开Excel文件，Alt+F11打开宏，修改HPCControlMacros 1Private Const HPC_ClusterScheduler = \"HEADNODE\" 5.运行 先使用Calculate on Desktop测试在本机上运行 再使用Calculate on Cloud来测试在云上运行，你会发现这次快很多，因为每一个单元格的计算都会发送给云的计算节点单独运算 例子2：在云上使用一个动态的workbook与第一个例子不同，这个例子实现并没有向云上的计算节点部署Excel文件，而是在运行过程中通过一个帮助程序来下载Excel 例子3：使用SOA服务的Excel和Azure上面两个例子都是使用Excel VBA来直接运行计算，我们还可以定制一个SOA Service，在这个Service里面，使用HPC/Excel库来做计算。我们还可以做一个定制的客户端，运行在桌面机上，使用云端的服务。这个Case和IBM Spectrum Symphony SOAM application已经基本一致了。 安装包编译SOA service和client安装SOA service运行示例代码","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"ityuhui.github.io/tags/bigdata/"},{"name":"distributed computing","slug":"distributed-computing","permalink":"ityuhui.github.io/tags/distributed-computing/"},{"name":"分布式计算","slug":"分布式计算","permalink":"ityuhui.github.io/tags/分布式计算/"},{"name":"大数据","slug":"大数据","permalink":"ityuhui.github.io/tags/大数据/"},{"name":"HPC","slug":"HPC","permalink":"ityuhui.github.io/tags/HPC/"}]},{"title":"如何写专利","slug":"how-to-write-patent","date":"2020-05-08T02:33:15.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2020/05/08/how-to-write-patent/","link":"","permalink":"ityuhui.github.io/2020/05/08/how-to-write-patent/","excerpt":"专利的三性：1. 新颖性以前没有","text":"专利的三性：1. 新颖性以前没有 2. 创新性相比较现有系统，有创造性 3. 实用性有用处 专利的命名：1. 系统、装置或者设备2. 方法其他 算法本身不能是专利，但是解决了某个实际问题的算法可以是专利，例如：压缩算法是专利 Linux的某个文件系统是专利 专利描述的技术不容易绕过","categories":[{"name":"技术方面的思考和总结","slug":"技术方面的思考和总结","permalink":"ityuhui.github.io/categories/技术方面的思考和总结/"}],"tags":[{"name":"patent","slug":"patent","permalink":"ityuhui.github.io/tags/patent/"}]},{"title":"计算机科学主要的研究领域","slug":"computer-science-research-areas","date":"2020-05-05T08:24:29.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2020/05/05/computer-science-research-areas/","link":"","permalink":"ityuhui.github.io/2020/05/05/computer-science-research-areas/","excerpt":"","text":"Mathematical foundations 数学基础 Theory of computation 计算机理论 Algorithms, data structures 算法与数据结构 Programming languages, compilers 编程语言, 编译器 Concurrent, parallel, distributed systems 并行, 分布式计算系统 Software engineering 软件工程 System architecture 计算机系统架构 Telecommunication, networking 通讯与网络 Databases 数据库 Artificial intelligence 人工智能 Computer graphics 计算机图形 Human–computer interaction 人机交互 Scientific computing 科学运算","categories":[{"name":"技术方面的思考和总结","slug":"技术方面的思考和总结","permalink":"ityuhui.github.io/categories/技术方面的思考和总结/"}],"tags":[{"name":"summary","slug":"summary","permalink":"ityuhui.github.io/tags/summary/"},{"name":"computer science","slug":"computer-science","permalink":"ityuhui.github.io/tags/computer-science/"}]},{"title":"Microsoft HPC Pack 2016 学习笔记","slug":"Microsoft-HPC-Pack-2016-Introduction","date":"2020-05-05T08:10:43.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2020/05/05/Microsoft-HPC-Pack-2016-Introduction/","link":"","permalink":"ityuhui.github.io/2020/05/05/Microsoft-HPC-Pack-2016-Introduction/","excerpt":"介绍Microsoft HPC Pack是微软的高性能分布式计算平台，类似于IBM Spectrum Symphony，是一种基于SOA架构的分布式计算框架。目前，它有三种部署方式如下，本文只介绍第一种。 on-premises, 部署在本地，可以把计算节点扩展到云上 hybird, 部署在本地，通常会把计算节点扩展到云上 on-demand 部署在云上","text":"介绍Microsoft HPC Pack是微软的高性能分布式计算平台，类似于IBM Spectrum Symphony，是一种基于SOA架构的分布式计算框架。目前，它有三种部署方式如下，本文只介绍第一种。 on-premises, 部署在本地，可以把计算节点扩展到云上 hybird, 部署在本地，通常会把计算节点扩展到云上 on-demand 部署在云上 on-premise部署1. 部署准备1.1 评估操作系统是否达到要求硬件要求头节点 CPU: 64位，推荐8核心以上，最小4核心 内存：推荐16 GB以上，最小8 GB 磁盘：推荐100 GB以上，最小50 GB 其他节点 CPU: 64位，推荐4核心以上，最小4核心 内存：推荐4 GB以上，最小2 GB 磁盘：推荐80 GB以上，最小50 GB 软件要求.NET Framework 4.6.1 (or later) 头节点： Windows Server 2016, Windows Server 2012 R2 计算节点：Windows Server 2019 (only for HPC Pack 2016 Update 3), Windows Server 2016, Windows Server 2012 R2, Windows Server 2012, Windows Server 2008 R2 SP1， 客户端节点：Windows 10, Windows 8.1 Linux node： Red Hat Enterprise Linux 7.0 - 7.6, Red Hat Enterprise Linux 6.7 - 6.10, CentOS-based 7.0 - 7.6, CentOS-based 6.7 - 6.10, Ubuntu Server 14.04 LTS, Ubuntu Server 16.04 LTS, Ubuntu Server 18.04 LTS, SUSE Linux Enterprise Server 12 1.2 评估是否需要High Availability 如果需要，就需要安装三个头节点配置为一个Service Fabric集群 1.3 决定是否需要远程数据库 1.4 决定需要多少个节点 计算节点，用于执行任务 代理节点(Windows Communication Foundation (WCF) broker nodes)，负责路由SOA服务 工作站节点（workstation nodes），可以临时用于执行任务 1.5 选择活动目录域 1.6 选择域账户来添加节点 1.7 为集群选择网络拓扑结构 1.8 准备两个证书用于节点之间的加密通讯 2. 部署头节点2.1 在头节点上安装Windows Server 2.2 将头节点加入活动目录域里 2.3 在前两个头节点上安装前置组件（可选） 这一步是可选的，如果需要配置多个头节点才需要 2.4 在最后一个头节点上安装Microsoft HPC Pack 3. 配置集群3.1 配置集群的网络 3.2 提供安装凭证 3.3 配置新加入的节点的命名规则 3.4 为部署导入或者创建证书 3.5 创建节点模板（可选） 3.6 创建用户（可选） 4. 向集群里添加Windows计算节点4.1 通过模板从物理机（bare metal）上部署节点 4.2 手工向集群添加节点 4.2.1 在计算节点上安装Windows操作系统 4.2.2 将计算节点加入域 4.2.3 在计算节点上安装Microsoft HPC Pack 2016 5. 向集群里添加Linux计算节点5.1 在计算节点上安装Linux操作系统 5.2 下载Linux计算节点安装文件在Windows头节点上执行Powershell命名 123Add-PSSnapin microsoft.hpc Get-HpcClusterRegistry -PropertyName InstallShare 5.3 搭建文件共享路径将5.2下载得到的文件共享给Linux计算节点 5.4 安装证书用于加密HPC节点之间的通讯 5.5 在Linux计算节点上安装Linux计算节点代理 1python setup.py -install -connectionstring:'&lt;connection string of the cluster&gt;' -certfile:'&lt;path to PFX certificate&gt;' HPC Job Manager使用HPC Job Manager，可以提交、监控和管理所有的计算任务。 基本的术语： Job, 一次计算任务 Task, 一个Job包含一个或者多个Task, Task不能脱离Job Queue, Job提交以后会放在Queue里面，等待调度和分配到计算节点上 HPC Job Scheduler Service, 运行在头节点上的一个服务，负责调度队列里面的Job/Task，分配资源、分发任务到计算节点、监控任务的执行过程。 教程Excel 2016 offloading to Azure cluster这个教程展示了将Excel 2016 放在Azure集群上运行 前提已经在本地的计算节点上安装好了Excel 2016和HPC Pack 2016 client utilities 步骤1. 在Azure上部署一个Excel集群， 设置头节点不要参加计算，因为头节点并没有安装Excel2. 激活Execl产品，你必须要有一个Office的License3. 使用Execl workbook offloading3.1 下载sample xlsb 3.2 在Excel 2016里将ConvertiblePricing_Complete.xlsb打开，并激活Excel Options -&gt; Customize Ribbon 3.3 在Develop ribbon，点击COM Add-Ins, 确认HPC Pack Excel COM Add-in已经成功载入 3.4 编辑Excel文件里的VBA宏HPCControlMacros 123456'change Private Const HPC_ClusterScheduler = \"hpchn01laj2kdgetycrw.southeastasia.cloudapp.azure.com\" toPrivate Const HPC_ClusterScheduler = \"&lt;headnode DNS name saved above&gt;\"'change Private Const HPC_DependFiles = \"D:\\tmp\\iaasexcel\\upload\\ConvertiblePricing_Complete.xlsb=ConvertiblePricing_Complete.xlsb\" toPrivate Const HPC_DependFiles = \"&lt;upload directory path&gt;\\ConvertiblePricing_Complete.xlsb=ConvertiblePricing_Complete.xlsb\"'change HPCExcelClient.OpenSession headNode:=HPC_ClusterScheduler, remoteWorkbookPath:=HPCWorkbookPath, UserName:=\"hpc\\hpcadmin\", Password:=\"********\" toHPCExcelClient.OpenSession headNode:=HPC_ClusterScheduler, remoteWorkbookPath:=HPCWorkbookPath, UserName:=\"&lt;domain&gt;\\&lt;username&gt;\", Password:=\"&lt;YourPassword&gt;\" 3.5 将Excel workbook拷贝到上面指定的HPC_DependsFiles目录里 3.6 调集worksheet里的Cluster按钮，workbook将在会Azure里计算 参考Overview of Microsoft HPC Pack 2016","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"distributed computing","slug":"distributed-computing","permalink":"ityuhui.github.io/tags/distributed-computing/"},{"name":"Microsoft","slug":"Microsoft","permalink":"ityuhui.github.io/tags/Microsoft/"},{"name":"HPC","slug":"HPC","permalink":"ityuhui.github.io/tags/HPC/"}]},{"title":"训练神经网络的基本流程","slug":"neural-network-trainning","date":"2020-05-03T10:14:41.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2020/05/03/neural-network-trainning/","link":"","permalink":"ityuhui.github.io/2020/05/03/neural-network-trainning/","excerpt":"1. 创建网络","text":"1. 创建网络 创建多层网络各层网络是全连接层或者卷积层 采样，池化2. 定义误差函数（损失函数）3. 设定学习率 (更新权重的步长)4. 给定权重的初值5. 根据输入，正向计算6. 得到输出，计算其与正确值之间的误差7. 误差反向传播8. 更新权重值（梯度下降法）9. 迭代5-8，直到误差收敛","categories":[{"name":"AI","slug":"AI","permalink":"ityuhui.github.io/categories/AI/"}],"tags":[{"name":"ai","slug":"ai","permalink":"ityuhui.github.io/tags/ai/"},{"name":"神经网络","slug":"神经网络","permalink":"ityuhui.github.io/tags/神经网络/"},{"name":"机器学习","slug":"机器学习","permalink":"ityuhui.github.io/tags/机器学习/"}]},{"title":"Windows平台下进程的资源限制(Job Object)","slug":"Process-Resource-Limis-Windows","date":"2020-04-08T11:58:56.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2020/04/08/Process-Resource-Limis-Windows/","link":"","permalink":"ityuhui.github.io/2020/04/08/Process-Resource-Limis-Windows/","excerpt":"介绍与Linux平台上的cgroups类似， Windows平台上也有限制进程资源使用的机制，叫做Job Object，这篇文章是我对微软官方文档的中文翻译，然后加上我自己写的示例代码，代码和官方文档的链接都在文末。","text":"介绍与Linux平台上的cgroups类似， Windows平台上也有限制进程资源使用的机制，叫做Job Object，这篇文章是我对微软官方文档的中文翻译，然后加上我自己写的示例代码，代码和官方文档的链接都在文末。 Job Object一个job object将一组进程管理成一个单元，它是可命名的、安全的、可共享的控制进程属性的对象。对一个job object的操作将会影响它管理的所有的进程，例如，可以通过修改job object来影响其管理的所有进程的working set的大小、优先级以及终止所有进程。 创建Jobs函数CreateJobObject用来创建一个job object。新创建出来的job object没有关联任何进程。 函数AssignProcessToJobObject可以将一个进程关联到一个job上，当进程被关联到job上之后，就无法再分开。但是一个进程可以被关联到多个嵌套的job上。 嵌套job是从Windows 8和Windows Server 2012才引入的，所以在之前的操作系统里，一个进程只能被关联到一个job object上，而且一旦关联就无法再分开。 当调用CreateJobObject创建job object的时候，可以给job object指定security descriptor。 管理Job关联的进程当一个进程关联到一个job之后，这个进程创建的子进程默认也会被关联到这个job上。（注意：CreateProcess函数创建的子进程会被自动关联，但是Win32_Process.Create创建的则不会。） 可以通过设置JOB_OBJECT_LIMIT_BREAKAWAY_OK或者JOB_OBJECT_LIMIT_SILENT_BREAKAWAY_OK来修改默认行为： 如果job有extended limit/JOB_OBJECT_LIMIT_BREAKAWAY_OK, 并且在创建父进程的时候指定了CREATE_BREAKAWAY_FROM_JOB，那么子进程不会被自动的关联到父进程的job object。 如果job有extended limit/JOB_OBJECT_LIMIT_SILENT_BREAKAWAY_OK，不需要在创建父进程的时候指定任何选项，子进程都不会自动被关联到父进程的job object。 如果job是嵌套的，那么层级里的父job的breakaway设置会影响到层级里的其他job所关联的子进程。 函数IsProcessInJob可以判定一个进程是否运行在一个job里。 函数TerminateJobObject可以终止一个job里关联的所有的进程的运行。 Job限制和通知job可以强制设置它所关联的每一个进程的working set大小、进程优先级以及执行时间等限制。如果job所关联的进程试图超过限制，有两种结果（默认是第一种）： 进程申请资源表面上返回成功，其实并没有被处理。 允许进程使用超过限制的资源，但是会触发一个通知。 函数SetInformationJobObject用于设置job的限制。以下是资源限制的种类： JOBOBJECT_BASIC_LIMIT_INFORMATION JOBOBJECT_BASIC_UI_RESTRICTIONS JOBOBJECT_CPU_RATE_CONTROL_INFORMATION JOBOBJECT_EXTENDED_LIMIT_INFORMATION JOBOBJECT_NOTIFICATION_LIMIT_INFORMATION 如果job是嵌套的，层级里的父job会影响子job 如果job有一个关联的I/O completion端口，它可以在资源超限后收到通知。当资源超限或者某个事件来到，系统会发送消息给completion端口。使用带有job object信息类JobObjectAssociateCompletionPortInformation和一个JOBOBJECT_ASSOCIATE_COMPLETION_PORT结构体指针的函数SetInformationJobObject可以将一个completion端口关联到job。注意最好是在job不活动的时候做这个关联，以降低丢失消息的风险。 如果job调用了PostQueuedCompletionStatus函数，所有的消息都会被job直接发送。某个线程必须使用GetQueuedCompletionStatus函数来监控complition端口从而拿到消息。 带有JobObjectNotificationLimitInformation信息类的限制的异常，并不能保证被发送给completion端口，带有JobObjectNotificationLimitInformationx的通知是可以保证的。 Job的资源账户job object记录了其关联的所有进程的基本资源信息（包括终止的进程），使用QueryInformationJobObject函数可以获取这些资源信息。 JOBOBJECT_BASIC_ACCOUNTING_INFORMATION JOBOBJECT_BASIC_AND_IO_ACCOUNTING_INFORMATION 如果一个job object是嵌套的，每一个子job的资源账户都会被累加到它的父job的资源账户上。 管理Job Object本身因指定的end-of-job时间限制到达，造成一个job object关联的所有进程都终止时，job object的状态会被设置为signaled。我们可以使用 WaitForSingleObject或者WaitForSingleObjectEx来监控job object来获得这个信号。 指定job object名称、使用OpenJobObject函数可以获得一个已存在的job object的handle。 使用CloseHandle函数可以管理一个job object handle。当一个job所关联的所有的进程都终止并且job的最后一个handle被关闭，这个job就将被销毁。但是，如果一个job带有JOB_OBJECT_LIMIT_KILL_ON_JOB_CLOSE标志，那么关闭job的最后一个handle，会强制终止它关联的所有进程并销毁job。如果一个嵌套的job带有JOB_OBJECT_LIMIT_KILL_ON_JOB_CLOSE标志，那么关闭这个job的handle会终止它以及它的子job的所有的进程。 使用Job Objects 来管理进程树从Windows 8和Windows Server 2012起，一个应用程序可以使用嵌套jobs来管理进程树。 但是之前的系统可以使用其他的方法来管理进程树。这里就不作介绍了。有需要可以看文末的参考。 嵌套Job嵌套job的层级在嵌套job里，每一个子job都包含了父job的进程的子集。如果一个已经在某个job里的进程被加到另外一个job里，如果这些job可以形成一个有效的层级并且没有任何一个job设置了UI限制，那么这些job就成为嵌套job 上图展示了一个包含七个进程的进程树的job层级。Job1是job2和job4的父job，它是job3的祖先。job2是job3的父亲。job3是进程P2,P3,P4的直接job 嵌套job也可以用于管理同级的兄弟进程，例如下图，Job1是Job2的父亲。job层级可能只包含进程树的一部分，例如，P0并不在job层级里。 创建一个嵌套job层级job层级里的进程可以用AssignProcessToJobObject函数显式的关联到job上，也可以在进程创建的时候自动的关联。job被创建以及进程被关联的顺序决定了层级是否可以被创建出来。 1. 显式关联所有的job object必须使用CreateJobObject创建，然后多次调用AssignProcessToJobObject，将每一个进程关联到每一个job上，为了确保层级有效，必须首先指定所有的进程到层级的根job上，然后指定进程的子集到直接的子job object上，以此类推。如果按照此顺序指定job,一个子job总是包含父job的进程的子集。如果顺序是随机的话，创建嵌套job将无法成功，AssignProcessToJobObject会返回失败。 2. 隐式关联当子进程创建的时候，会自动的关联到它的父进程的job链上的所有的job上。直接job object允许脱离（breakaway），子进程脱离直接job object和job链上的每一个job object, 直到遇到了不允许脱离的job object。如果直接job object不允许脱离，那么即使job链上的父job允许脱离，该进程也不能再脱离。 嵌套Job里的限制和通知限制设置在父job上的限制，会强制应用到子job上。子job的生效的限制值要比父job严格。举例来说， 如果一个子job的优先级类是ABOVE_NORMAL_PRIORITY_CLASS，而父job的优先级类是NORMAL_PRIORITY_CLASS，那么子job的生效的优先级是NORMAL_PRIORITY_CLASS。 但是，如果子job的优先级类是BELOW_NORMAL_PRIORITY_CLASS，那么生效的优先级类是BELOW_NORMAL_PRIORITY_CLASS 下列几种限制都由生效值的问题： priority class affinity commit charge per-process execution time limit scheduling class limit working set minimum and maximum 通知当特点的事件（例如创建新进程、资源限制越界）发生，一个消息会被发送到job关联的I/O completion端口。job也可以接收消息。对于一个非嵌套的job，消息会被发送到该job关联的completion端口。对于一个嵌套的job,消息会被发送到该job所在的job链上的每一个job关联的completion端口。所以说子job不必一定有自己的completion端口。 嵌套Job的资源账户嵌套job的资源账户信息描述了该job关联的每一个进程的资源使用情况，包括子job的。job链上的每一个job都聚合了它自己关联的进程以及它所在的job链上的子job所关联的进程。 终止嵌套Job当嵌套job里的一个job终止，系统将会终止这个job以及它的子job关联的所有进程。终止的进程的资源将会被父job来计入。 与普通job一样，嵌套job也必须有JOB_OBJECT_TERMINATE访问权限。 Job Object安全和访问权限可以控制对Job jobect的访问 当使用CreateJobObject创建job的时候，可以指定一个security descriptor，如果没有指定，job object会有一个默认的security descriptor。默认security descriptor的访问控制列表ACL来自于创建者的primary或者impersonation令牌。 当使用 CreateJobObject 创建job后，返回的handle具有JOB_OBJECT_ALL_ACCESS权限。 当使用 OpenJobObject，系统会检查请求访问权限。 如果一个job object在一个嵌套job层级里，调用者将具有子job的权限。 如果你想读写job object的SACL, 则需要请求一个job object的ACCESS_SYSTEM_SECURITY权限。 必须对job关联的每一个进程都设置安全限制，而不是设置job object本身。 示例代码ResLimitsOnWin on Github 参考Job Objects","categories":[{"name":"Windows编程","slug":"Windows编程","permalink":"ityuhui.github.io/categories/Windows编程/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"ityuhui.github.io/tags/Windows/"}]},{"title":"Excel Workbook Offloading to IBM Spectrum Symphony","slug":"Excel-Workbook-Offloading-to-IBM-Spectrum-Symphony","date":"2020-04-04T06:29:22.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2020/04/04/Excel-Workbook-Offloading-to-IBM-Spectrum-Symphony/","link":"","permalink":"ityuhui.github.io/2020/04/04/Excel-Workbook-Offloading-to-IBM-Spectrum-Symphony/","excerpt":"将Excel的计算分发到IBM Spectrum Symphony集群上进行 背景IBM Spectrum Symphony是基于SOA架构的分布式计算框架，可以将任务调度到集群上计算并汇总计算结果。与之类似的框架还有Apache Hadoop, Apache Spark, Microsoft HPC Pack。受益于其底层优秀的资源调度框架EGO、由C++实现的中间件，Symphony的性能和可扩展性都极为优秀，在金融衍生品的定价以及风险模拟等金融领域得到广泛的应用。 很多数据分析师喜欢使用Microsoft Excel来进行数据的收集、建模和分析，但是，当金融模型的数据量很大，或者模型的计算非常复杂时，在单机上执行Excel数学运算将会极其耗费时间，所以，将Exel workbook上的数据分发到集群进行分布式计算非常必要。IBM Spectrum Symphony支持这一应用场景。","text":"将Excel的计算分发到IBM Spectrum Symphony集群上进行 背景IBM Spectrum Symphony是基于SOA架构的分布式计算框架，可以将任务调度到集群上计算并汇总计算结果。与之类似的框架还有Apache Hadoop, Apache Spark, Microsoft HPC Pack。受益于其底层优秀的资源调度框架EGO、由C++实现的中间件，Symphony的性能和可扩展性都极为优秀，在金融衍生品的定价以及风险模拟等金融领域得到广泛的应用。 很多数据分析师喜欢使用Microsoft Excel来进行数据的收集、建模和分析，但是，当金融模型的数据量很大，或者模型的计算非常复杂时，在单机上执行Excel数学运算将会极其耗费时间，所以，将Exel workbook上的数据分发到集群进行分布式计算非常必要。IBM Spectrum Symphony支持这一应用场景。 实现方式1. Execl VBA模式将Excel作为客户端，当点击workbook/sheet上的宏计算按钮之后，Excel通过IBM Spectrum Symphony COM SDK连接Symphony集群，集群把计算任务和workbook分发到计算节点上，由服务端程序打开Excel workbook进行计算，计算结果返回给客户机器的Excel后，Excel将其填入单元格内。 这种模式下，服务端也可能是由编程语言自制的程序，Excel客户端只发来数据，不发来workbook, 服务端将发来的数据进行处理，返回给Excel客户端。 2. 定制客户端和服务端程序的模式使用任意一种编程语言编写自制的客户端程序，将参数和Excel workbook通过IBM Spectrum Symphony SDK发送给Symphony集群上自制的服务端程序，由服务端程序进行计算，计算结果返回给客户端，客户端再将结果进行后续的处理。 这种模式下，服务端也可根据需要，打开计算节点上的Excel对发送过来的workbook进行处理，将结果返回给客户端。 其实，如果把客户端实现为基于IBM Spectrum Symphony COM SDK的Excel workbook和宏, 把服务端实现为打开Excel workbook执行宏，这种模式就成为了第一种，所以我们可以认为，第一种模式是第二种模式的一个特例。接下来，我会展示一个第一种模式的实例来详细介绍一下。 Excel VBA模式 实例1. 编写服务端和客户端程序a) 编写Excel客户端首先使用Excel新建一个workbook, Alt+F11进入Visual Basic for Application界面。 点击Tools-&gt;Reference，Browse, 找到并选中IBM Spectrum Symphony COM SDK的DLL文件。 然后，新建类模块MyMessage，用于在客户端和服务端传送消息。 第三，新建一个宏SymphonyClient, 用于放置客户端VBA代码，下面是一个基本的框架： 123456789'' 初始化'' 建立连接'' 发送计算'' 接收计算结果'' 在单元格内显示 第四，在Excel workbook的界面上，新增一个按钮，将按钮的响应函数指向上面一步写好的函数上 b) 编写服务端打开上面创建的workbook, 新建一个宏SymphonyService, 用于放置服务端VBA代码 1'' 实际的计算逻辑代码 使用Symphony C++ SDK，编写打开Excel workbook并执行宏的代码，用于启动Excel计算 2. 打包和部署服务端在Symphony Web管理界面上，找到或者新建一个拥有合适的resource group的consumer，在resource plan界面下，选择好slot分配。 在服务端的Application Profile文件里，填入正确的consumer。 将服务端打包，使用soamdeploy部署到Repository Server（RS）上，使用soamreg命令注册服务端程序，再通过soamview查看服务端程序是否已经激活。 3. 运行客户端在Excel workbook上，点击上面新建好的按钮，计算将会发送给Symphony集群，等计算完成后数据会从集群发送回来，Excel workbook收到后更新单元格上的数据。","categories":[{"name":"大数据和分布式计算","slug":"大数据和分布式计算","permalink":"ityuhui.github.io/categories/大数据和分布式计算/"}],"tags":[{"name":"bigdata","slug":"bigdata","permalink":"ityuhui.github.io/tags/bigdata/"},{"name":"distributed computing","slug":"distributed-computing","permalink":"ityuhui.github.io/tags/distributed-computing/"},{"name":"分布式计算","slug":"分布式计算","permalink":"ityuhui.github.io/tags/分布式计算/"},{"name":"大数据","slug":"大数据","permalink":"ityuhui.github.io/tags/大数据/"},{"name":"Symphony","slug":"Symphony","permalink":"ityuhui.github.io/tags/Symphony/"}]},{"title":"kubernetes scheduler 介绍","slug":"kubernetes-scheduler-introduction","date":"2020-04-03T15:09:30.000Z","updated":"2020-06-20T12:32:48.869Z","comments":true,"path":"2020/04/03/kubernetes-scheduler-introduction/","link":"","permalink":"ityuhui.github.io/2020/04/03/kubernetes-scheduler-introduction/","excerpt":"一、什么是 kubernetes schedulerkubernetes scheduler 是 kubernetes 的核心组件，负责给需要执行的pod选择合适的node。","text":"一、什么是 kubernetes schedulerkubernetes scheduler 是 kubernetes 的核心组件，负责给需要执行的pod选择合适的node。 二、kubernetes scheduler 工作流程kube-scheduler在API server处留有Watcher, 当有新的pod请求到达后，kube-scheduler查看pod的spec里是否指定了执行的node, 如果有，就忽略这个pod, 如果没有，就为这个pod启动调度流程，找到一个执行节点，将其回填回API server的pod信息里。 各节点上的kubelet从API server处观察到有pod的执行节点是自己所在的节点的时候，就在自己所在的节点上，创建并执行pod。 具体的调度（查找合适的执行节点）过程如下 第一阶段：预选预选的作用，是找到满足条件的节点，如具有SSD硬盘，系统内存大于某个值，去掉不满足条件的节点。以下是几个比较重要的策略： 防止过度提交 反亲和 亲和 污染和容忍 第二阶段：优选预选可能找到多个满足条件的node, 优选阶段将按照一些规则对其进行打分并汇总，打分高者最后会被选中。以下是几个优选的策略： 节点漫延 反亲和 亲和 打分后线性相加，得到最后的总分，分高的node将会被选中。 三、kubernetes scheduler 源代码分析kubernetes scheduler 是一个单独的进程，但是从代码逻辑上，分为两个部分：cmd和pkg cmd接收命令行参数 pkg调度的核心代码 四、如何扩展scheduler有的时候，k8s 自带的kube-scheduler无法满足我们自己的需求，这时我们需要来扩展scheduler，目前，扩展schedule有以下几种方式： 1. 编写自己的sheduler, 与kube-scheduler共存优点：自己有很大控制权。 缺点：不能利用到kube-scheduler已有的逻辑，需要自己从头写。 2. 使用externder/webhook参考 优点：可以利用kube-scheduler里的已有的逻辑 缺点：http连接可能会有性能问题； 只能编写一个扩展器，插入到一个地点，无法做到多个扩展共同生效。 3. 使用scheduler framework参考 kuber-scheduler提供的扩展框架，可以编写我们自己的插件，将其插入kube-sheduler的执行流程，是未来主要的扩展方式。","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/tags/kubernetes/"},{"name":"k8s","slug":"k8s","permalink":"ityuhui.github.io/tags/k8s/"}]},{"title":"使用libyaml","slug":"libyaml-introduction","date":"2020-03-30T13:52:19.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2020/03/30/libyaml-introduction/","link":"","permalink":"ityuhui.github.io/2020/03/30/libyaml-introduction/","excerpt":"介绍libyaml是用于解析和生成yaml文件的C语言库，是yaml官方推荐的C语言库之一。","text":"介绍libyaml是用于解析和生成yaml文件的C语言库，是yaml官方推荐的C语言库之一。 读取本文只关注于读取yaml文件，没有涉及生成和修改。 libyaml支持三种读取模式： 基于token我个人觉得已经可以被基于event的模式取代 基于event这是官方页面的实例代码介绍的模式，应用程序处理各种yaml定义的事件 STREAM-START STREAM-END DOCUMENT-START DOCUMENT-END ALIAS SCALAR SEQUENCE-START SEQUENCE-END MAPPING-START MAPPING-END 来读取yaml文件内的元素 stream ::= STREAM-START document* STREAM-END document ::= DOCUMENT-START node DOCUMENT-END node ::= ALIAS | SCALAR | sequence | mapping sequence ::= SEQUENCE-START node* SEQUENCE-END mapping ::= MAPPING-START (node node)* MAPPING-END 这种方法需要自己实现一个状态机，根据事件来判断下一步处理的事件，同时读取元素。 基于document使用这种模式，libyaml将整个yaml读入内存，应用程序不需要再处理上面两种模式里的事件或者token, 只需要按照libyaml在内存中的数据结构安排，将其遍历出来，比较方便，也类似于libxml的模式。 使用这种模式，我实现了读取kubeconfig yaml文件，代码在 kubeyaml","categories":[{"name":"C语言","slug":"C语言","permalink":"ityuhui.github.io/categories/C语言/"}],"tags":[{"name":"libyaml","slug":"libyaml","permalink":"ityuhui.github.io/tags/libyaml/"}]},{"title":"以太坊的一些基本概念","slug":"ethereum-introduction-2019","date":"2019-12-21T12:50:00.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2019/12/21/ethereum-introduction-2019/","link":"","permalink":"ityuhui.github.io/2019/12/21/ethereum-introduction-2019/","excerpt":"介绍以太坊是一个区块链平台，提供了运行智能合约的虚拟机，利用这个平台，任何人都可以快速的开发出一个自己的基于区块链的应用，例如一种加密货币，而不需要从最底层的区块链一步步的实现。","text":"介绍以太坊是一个区块链平台，提供了运行智能合约的虚拟机，利用这个平台，任何人都可以快速的开发出一个自己的基于区块链的应用，例如一种加密货币，而不需要从最底层的区块链一步步的实现。 概念智能合约智能合约指的是运行在以太坊网络上的分布式的应用程序。 Gas智能合约在以太坊网络上的每一个节点上执行，需要消耗的电能和时间，因此引入Gas来计算成本。Gas指的是以太坊底层的虚拟机EVM执行代码的代价。如果你的智能合约程序用光了账户里的Gas，那么你的计算程序就将会被以太坊网络拒绝。 Gas的价格由市场决定，与比特币的交易费类似。如果你出价高，网络中的节点会优先计算你的事务。通常来说，读取状态时免费，存储状态时收费。 分布式应用程序 dApp分布式应用程序指的是服务端放在以太坊网络上的智能合约程序。它不并需要将全部的状态和计算都放在区块链上，因为那很昂贵。但是一个分布式程序最终必须将可信任状态存放到以太坊区块链上以供任何人读取。 以太坊组织在Github上有一些关于分布式应用程序dApp的参考和例子 dApp 客户端一个dApp 客户端是以太坊区块链上的程序的前端，通常用Javascript或者Go/Rust编写。 dApp 浏览器是一个可以运行dApp Javascript客户端程序的应用程序，连接以太坊节点、提供一个账户接口。 Mist是官方的以太坊dApp浏览器。 以太坊节点节点保存着区块链的副本，可以执行所有的事务来确认结果状态，运行着geth或者parity 节点需要知道下载哪个区块链、和哪个peer通讯。 通常使用docker来运行节点客户端，但是也可以使用Infra在本机运行（主要是为了测试和开发） 如果你向用户分发dApp客户端，你不必提供对以太坊节点的访问方法。用户只需要运行dApp浏览器就可以了。 以太坊令牌令牌就是在一个分布式哈希表里的通过API来做加运算和减运算的一些数字，通常用于去中心化的交互、资产所有权证明、投票权证明等。 REC20/ERC223/ERC777/ERC827 令牌用于定义令牌的协议 ERC721/NFT 令牌定义了一个不可替代的令牌的标准。所谓“不可替代”，指的是每一个令牌都不等于其他令牌，都有自己的独一无二的属性。 智能合约的接口你可以使用 JSON RPC API与智能合约交互。geth和parity都提供了命令行/浏览器用于交互。 如果你想编程与智能合约交互，那么可以使用web3.js, ethjs, abigen，你也可以写自己的客户端库来操作 JSON PRC API。 为了测试和开发，可以使用Ganache来运行一个本地的以太坊节点。 当你部署一个智能合约的时候，你所有要做的，就是向地址0 （0x0）发送一个事务（将合约的字节码作为参数） Truffle, Embark, Populous, Perigord 和其他一旦你开始写智能合约，你所作的事情会有大量的重复：编译源代码成为字节码、部署字节码到网络上、测试部署的合约等等。 Truffle, Embark, Populous, Perigord 这些框架标准化和自动化了这些细节，他们提供了一个很好的编写、部署和测试合约的开发流程。 其中最受欢迎的是用Node编写Truffle。 当你第一次写合约的时候，最好不要使用这些框架，而是从头手写。这样可以让自己理解这些框架是干什么用的。当你熟悉了怎么手写智能合约之后，再使用这些框架。 ETHPMETHPM是一个去中心化的智能合约的包的仓库。使用它，你可以复用其他知名的合约和库，减少代码的重复。 主要的网络Mainnet: 是主以太坊网络 Repsten: 是主要的测试网络，使用工作量证明。 账户 钱包一个以太坊账户是一个私钥和地址对，他们用来存储以太币，无需Gas来创建，所有以太坊网络上的事务都起源于一个账户，合约不能发起一个事务。 一个钱包可能是下列二者之一： 1） 一个使用你的账户创建和发送事务的接口 2） 只是一个发送和接收以太的智能合约 EVM你的智能合约会被编译成一种机器码，它们会运行于网络上每一个节点的EVM（以太坊虚拟机）里。Solidity 是官方的编写智能合约的语言。","categories":[{"name":"区块链","slug":"区块链","permalink":"ityuhui.github.io/categories/区块链/"}],"tags":[{"name":"block chain","slug":"block-chain","permalink":"ityuhui.github.io/tags/block-chain/"},{"name":"ethereum","slug":"ethereum","permalink":"ityuhui.github.io/tags/ethereum/"}]},{"title":"Hyperledger Fabric的简单介绍","slug":"Hyperledger-Fabric-Introduction","date":"2019-12-16T13:36:54.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2019/12/16/Hyperledger-Fabric-Introduction/","link":"","permalink":"ityuhui.github.io/2019/12/16/Hyperledger-Fabric-Introduction/","excerpt":"介绍Hyperledger是Linux基金会旗下的项目，里面包含了多个区块链的实现以及辅助项目。如Fabric, Indy, Iroha, Sawtooth等。","text":"介绍Hyperledger是Linux基金会旗下的项目，里面包含了多个区块链的实现以及辅助项目。如Fabric, Indy, Iroha, Sawtooth等。 FabricFabric是Hyperledger项目里最早也是目前应用最广泛的区块链项目，最初由IBM开发，后来捐助给基金会。 组成 客户端应用程序 认可节点（chaincode也就是智能合约运行在这上面，认可节点同时也作为提交节点） 提交节点 排序服务器 账本 流程 客户端应用程序 向 认可节点 发送事务请求； 认可节点开始认可（模拟运行），并把签名的认可结果发回客户端应用程序； 客户端应用程序然后再提交到 排序服务器上（之前使用kafka，自v1.14.1后改用raft); 排序服务器通知提交节点创建一个block，提交到账本上，完成一次事务。","categories":[{"name":"区块链","slug":"区块链","permalink":"ityuhui.github.io/categories/区块链/"}],"tags":[{"name":"block chain","slug":"block-chain","permalink":"ityuhui.github.io/tags/block-chain/"},{"name":"hyperledger","slug":"hyperledger","permalink":"ityuhui.github.io/tags/hyperledger/"}]},{"title":"使用kubebuilder创建kubernetes的operator","slug":"kuberbuild-k8s-operator","date":"2019-10-06T09:04:20.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2019/10/06/kuberbuild-k8s-operator/","link":"","permalink":"ityuhui.github.io/2019/10/06/kuberbuild-k8s-operator/","excerpt":"介绍在kubernetes（以下简称k8s）里，operator指的是由CRD和controller共同构成的某项业务。CRD负责表示业务数据，controller负责业务操作（对业务数据的修改），两者共同完成某项业务在k8s里的运营。 创建CRD不需要编写程序，只需要写yaml文件，然后使用kubectrl命令部署到k8s里面就可以了，CRD部署到k8s之后，数据是存储在etcd里面的，只能手工（例如使用kubectrl）查询和修改，并没有什么实际作用，要想自动完成实际的业务，需要controller来实现。","text":"介绍在kubernetes（以下简称k8s）里，operator指的是由CRD和controller共同构成的某项业务。CRD负责表示业务数据，controller负责业务操作（对业务数据的修改），两者共同完成某项业务在k8s里的运营。 创建CRD不需要编写程序，只需要写yaml文件，然后使用kubectrl命令部署到k8s里面就可以了，CRD部署到k8s之后，数据是存储在etcd里面的，只能手工（例如使用kubectrl）查询和修改，并没有什么实际作用，要想自动完成实际的业务，需要controller来实现。 创建controller需要编程，controller的基本的流程是： 监听CRD的变化通过向API server放置watch/informer，当CRD发生变化，API server会通知controller 操作根据业务需要，对获得的CRD或者k8s里的其他资源进行修改 写回将变更的CRD信息写回API server 其中，第一步和第三步都可以通过REST操作来完成，所以理论上使用任何的编程语言都可以编写controller，但是，k8s社区已经把这些操作都封装成了各种语言的包来调用，省去了我们直接操作REST的不方便（特别是鉴权），在这些语言的包里，最推荐的无疑是k8s的原生语言golang编写的client-go 虽然有了client-go，我们还是需要自己编写很多的与具体业务无关的基础框架代码，例如监听CRD变化，写回状态，以及编写CRD的yaml，为了加快Operator的编写，k8s社区提供了kubebuilder，它可以为我们生成基础框架代码和CRD的yaml，我们只需要填写业务的数据成员和业务代码就可以了。 安装安装 kubebuilderReference 安装 kustomize使用初始化123go mod init module_namekubebuilder init --domain example.com 创建API和controller1kubebuilder create api --group ego --version v1 --kind Activity 运行12make install # 安装CRDmake run # 启动controller 部署12make docker-build docker-push IMG=yuhuixa/manager-controllermake deploy 开发增加对象数据参数12345678910111213141516// ActivitySpec defines the desired state of Activitytype ActivitySpec struct &#123; Command string `json:\"command\"` Host string `json:\"host\"` // +optional Execuser string `json:\"execuser\"` // +optional Execcwd string `json:\"execcwd\"` // +optional Envs []string `json:\"envs\"`&#125;// ActivityStatus defines the observed state of Activitytype ActivityStatus struct &#123; ProSta string `json:\"prosta\"`&#125; 123make &amp;&amp; make install &amp;&amp; make runkustomize build config/default # 重新渲染yamlkubectl apply -f config/samples 实现接口 Reconcile12345678910111213141516171819202122232425262728import ( \"context\" \"fmt\" \"strings\" \"github.com/go-logr/logr\" corev1 \"k8s.io/api/core/v1\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" ctrl \"sigs.k8s.io/controller-runtime\" \"sigs.k8s.io/controller-runtime/pkg/client\" egov1 \"symoperator/api/v1\")func (r *VirtulMachineReconciler) Reconcile(req ctrl.Request) (ctrl.Result, error) &#123; ctx := context.Background() log := r.Log.WithValues(\"activity\", req.NamespacedName) activity := &amp;egov1.Activity&#123;&#125; if err := r.Get(ctx, req.NamespacedName, activity); err != nil &#123; log.Error(err, \"unable to fetch activity\") &#125; else &#123; fmt.Println(\"activity.Spec.Command: \", activity.Spec.Command) fmt.Println(\"activity.Spec.Host: \", activity.Spec.Host) fmt.Println(\"activity.Status.ProSta: \" + activity.Status.ProSta) &#125;&#125; 一些有用的参考代码获得系统pod123456789podList := &amp;corev1.PodList&#123;&#125;err := r.List(ctx, podList, client.InNamespace(\"kube-system\"))if err != nil &#123; fmt.Printf(\"failed to list pods in namespace default: %v\\n\", err)&#125; else &#123; for _, pod := range podList.Items &#123; fmt.Println(pod.Spec.NodeName) &#125;&#125; 创建一个只运行一次的pod1234567891011121314151617181920212223podName := \"pod-sample-\" + strconv.FormatInt(time.Now().Unix(), 10)podCmd := []string&#123;\"sleep\"&#125;podArgs := []string&#123;\"50\"&#125;pod := &amp;corev1.Pod&#123; ObjectMeta: metav1.ObjectMeta&#123; Namespace: \"default\", Name: podName, &#125;, Spec: corev1.PodSpec&#123; Containers: []corev1.Container&#123; corev1.Container&#123; Image: \"ubuntu\", Name: \"ubuntu\", Command: podCmd, Args: podArgs, &#125;, &#125;, RestartPolicy: \"Never\", &#125;,&#125;// c is a created client._ = r.Create(ctx, pod) 参考 使用kubebuilder开发kubernetes CRD K8S resource CURD samples","categories":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/categories/kubernetes/"}],"tags":[{"name":"kubernetes","slug":"kubernetes","permalink":"ityuhui.github.io/tags/kubernetes/"},{"name":"k8s","slug":"k8s","permalink":"ityuhui.github.io/tags/k8s/"}]},{"title":"libxml2 删除节点以后出现空行怎么办","slug":"libxml2-remove-blank-line","date":"2019-08-14T09:05:03.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2019/08/14/libxml2-remove-blank-line/","link":"","permalink":"ityuhui.github.io/2019/08/14/libxml2-remove-blank-line/","excerpt":"问题的产生使用libxml2操作XML的时候，有的时候会调用 12xmlUnlinkNode(node_to_del);xmlFreeNode(node_to_del); 来删除节点，但是执行了之后，保存成XML文件的时候，会在删除的节点那一行显示出一个空行，很不美观。","text":"问题的产生使用libxml2操作XML的时候，有的时候会调用 12xmlUnlinkNode(node_to_del);xmlFreeNode(node_to_del); 来删除节点，但是执行了之后，保存成XML文件的时候，会在删除的节点那一行显示出一个空行，很不美观。 问题的原因xmlNodePtr指向的元素，其实并不全是XML的元素节点（XML_ELEMENT_NODE），还会有一些用于缩进显示的节点（XML_TEXT_NODE），在删除元素节点的时候，需要把这个元素节点之前的文本节点也删除掉。 实例代码123456789node_to_del = xml;node_for_text_indent = xml-&gt;prev;xml = xml-&gt;next;xmlUnlinkNode(node_to_del);xmlFreeNode(node_to_del);xmlUnlinkNode(node_for_text_indent); // delete the useless TEXT indent nodexmlFreeNode(node_for_text_indent); 注意事项要删除元素节点前面（-&gt;prev）的文本节点，不要删除元素节点后面（-&gt;next）的文本节点。","categories":[{"name":"C语言","slug":"C语言","permalink":"ityuhui.github.io/categories/C语言/"}],"tags":[{"name":"c","slug":"c","permalink":"ityuhui.github.io/tags/c/"},{"name":"libxml2","slug":"libxml2","permalink":"ityuhui.github.io/tags/libxml2/"}]},{"title":"使用 Visual Studio 2015 编写Windows平台下的OpenGL程序","slug":"using-vs2015-and-glut-to-develop-opengl-program-on-Windows","date":"2016-03-01T01:49:13.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2016/03/01/using-vs2015-and-glut-to-develop-opengl-program-on-Windows/","link":"","permalink":"ityuhui.github.io/2016/03/01/using-vs2015-and-glut-to-develop-opengl-program-on-Windows/","excerpt":"OpenGL是跨平台的三维图形库，本文介绍如何使用Visual Studio ( VC++ ) 2015搭建Windows平台下的OpenGL开发环境","text":"OpenGL是跨平台的三维图形库，本文介绍如何使用Visual Studio ( VC++ ) 2015搭建Windows平台下的OpenGL开发环境 无需下载笔者使用的Windows 7 Professional，在安装了Visual Studio 2015之后，默认已有OpenGL的库文件和头文件。 下载freeglutfreeglut是一个小型的图形工具库，用于提供创建和关闭窗口，Windows事件循环，响应鼠标键盘事件等功能，特别适宜于编写OpenGL小型程序，有了它，我们无需再使用MFC，QT等大型的图形框架（GUI Framework）。 到OpenGL的官网，找到freeglut的下载地址，里面有源代码和预编译二进制两种包，为了简单，笔者下载了预编译好的二进制包。 建立工程1. 新建工程打开VS2015，新建一个Win32 Console Application，名字为openglsam, 其他选择默认。 2. 设置正确的Solution Platforms将工具栏上Solution Platforms设置为x64 3. 配置头文件和库文件依赖打开Project –&gt; openglsam Properites –&gt; C/C++ –&gt; General –&gt; Additional Include Directories加入freeglut里的include目录 打开Project –&gt; openglsam Properites –&gt; Linker –&gt; General –&gt; Additional Library Directories加入freeglut里的lib/x64目录 打开Project –&gt; openglsam Properites –&gt; Linker –&gt; Input –&gt; Additional Dependencies加入freeglut.lib 4. 拷贝动态库文件将freeglut/bin/x64/freeglut.dll拷贝到项目openglsam目录 openglsam\\x64\\Debug下 5. 编写代码https://github.com/ityuhui/openglsam 评论","categories":[{"name":"Windows编程","slug":"Windows编程","permalink":"ityuhui.github.io/categories/Windows编程/"}],"tags":[{"name":"Windows","slug":"Windows","permalink":"ityuhui.github.io/tags/Windows/"},{"name":"OpenGL","slug":"OpenGL","permalink":"ityuhui.github.io/tags/OpenGL/"}]},{"title":"C++ 使用 libcurl","slug":"C-Plus-Plus-uses-libcurl","date":"2016-02-01T19:22:40.000Z","updated":"2020-06-16T13:14:37.133Z","comments":true,"path":"2016/02/02/C-Plus-Plus-uses-libcurl/","link":"","permalink":"ityuhui.github.io/2016/02/02/C-Plus-Plus-uses-libcurl/","excerpt":"简介使用C++编写http客户端程序，主要有下面两个方法： socket自己组装http包，向server的80端口发起请求，接收响应，处理。 http library使用libcurl库，其他知名的还有boost::asio,ACE，目前，libcurl的应用比较广泛。","text":"简介使用C++编写http客户端程序，主要有下面两个方法： socket自己组装http包，向server的80端口发起请求，接收响应，处理。 http library使用libcurl库，其他知名的还有boost::asio,ACE，目前，libcurl的应用比较广泛。 获得libcurl到官方网站下载源代码包到本地例如我的目录 $home/opt/libcurl 编译源代码 ./configuremake 得到静态库 libcurl.a其实也得到了动态库，但是为了简单，我没有使用。 拷贝头文件将include/curl目录拷贝到/usr/local/include下面 其实OSX系统自带libcurl/usr/lib/libcurl.dylib，也可以链接使用 使用libcurl创建工程，将 libcurl.a拷贝到此工程目录下https://github.com/ityuhui/mycurlsample 编写程序","categories":[{"name":"网络编程","slug":"网络编程","permalink":"ityuhui.github.io/categories/网络编程/"}],"tags":[{"name":"C-plus-plus","slug":"C-plus-plus","permalink":"ityuhui.github.io/tags/C-plus-plus/"},{"name":"C++","slug":"C","permalink":"ityuhui.github.io/tags/C/"},{"name":"libcurl","slug":"libcurl","permalink":"ityuhui.github.io/tags/libcurl/"}]},{"title":"C++ STL里的容器","slug":"C-Data-Structure","date":"2016-02-01T14:10:43.000Z","updated":"2020-06-16T13:19:15.909Z","comments":true,"path":"2016/02/01/C-Data-Structure/","link":"","permalink":"ityuhui.github.io/2016/02/01/C-Data-Structure/","excerpt":"顺序容器：vector: 数组实现，单向，相当于Java的 ArrayListlist： 双向链表，相当于Java的 LinkedListdeque：双向队列","text":"顺序容器：vector: 数组实现，单向，相当于Java的 ArrayListlist： 双向链表，相当于Java的 LinkedListdeque：双向队列 关联容器，用树实现map hash容器unordered_map 容器适配器，使用容器实现stack：实现deque实现queue：使用deque实现priority_queue：使用vector实现","categories":[{"name":"C++","slug":"C","permalink":"ityuhui.github.io/categories/C/"}],"tags":[{"name":"C-plus-plus","slug":"C-plus-plus","permalink":"ityuhui.github.io/tags/C-plus-plus/"},{"name":"stl","slug":"stl","permalink":"ityuhui.github.io/tags/stl/"}]},{"title":"Notes for Learning Javascript Design Patten","slug":"Notes-for-Learning-Javascript-Design-Patten","date":"2015-04-15T20:57:30.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2015/04/16/Notes-for-Learning-Javascript-Design-Patten/","link":"","permalink":"ityuhui.github.io/2015/04/16/Notes-for-Learning-Javascript-Design-Patten/","excerpt":"设计模式的分类：创建型设计模式：Constructor, Factory, Abstract, Prototype, Singleton and Builder 结构型设计模式Decorator, Facade, Flyweight, Adapter and Proxy 行为型设计模式Iterator, Mediator, Observer and Visitor Tips:Javascript是一门没有“类”的语言，但是可以用function来模拟”类”","text":"设计模式的分类：创建型设计模式：Constructor, Factory, Abstract, Prototype, Singleton and Builder 结构型设计模式Decorator, Facade, Flyweight, Adapter and Proxy 行为型设计模式Iterator, Mediator, Observer and Visitor Tips:Javascript是一门没有“类”的语言，但是可以用function来模拟”类” The Constructor Pattern这是Javascript特有的模式，其实就是传统面向对象编程语言里的类的构造函数 1234var car1=new Car();function Car()&#123; this.toString = function()&#123;&#125; toString函数会在每个对象中存在一份，所以应该使用prototype 12Car.prototype.toString = function () &#123;&#125;;","categories":[],"tags":[]},{"title":"Python装饰器模式","slug":"python-decorator","date":"2015-03-22T12:15:47.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2015/03/22/python-decorator/","link":"","permalink":"ityuhui.github.io/2015/03/22/python-decorator/","excerpt":"123@decodef foo(): pass","text":"123@decodef foo(): pass 其实@只是个语法糖, 可以翻译成 1foo=deco(foo) deco函数要定义成嵌套函数，并且返回内嵌套函数，这样才能修改foo 参考","categories":[{"name":"Python","slug":"Python","permalink":"ityuhui.github.io/categories/Python/"}],"tags":[{"name":"python","slug":"python","permalink":"ityuhui.github.io/tags/python/"},{"name":"装饰器","slug":"装饰器","permalink":"ityuhui.github.io/tags/装饰器/"}]},{"title":"对数据结构的简单总结","slug":"data-structure-summary","date":"2015-03-11T12:59:23.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2015/03/11/data-structure-summary/","link":"","permalink":"ityuhui.github.io/2015/03/11/data-structure-summary/","excerpt":"底层在数据结构的范畴里，底层物理实现只有两种： 数组 array 链表 linked","text":"底层在数据结构的范畴里，底层物理实现只有两种： 数组 array 链表 linked 高层最常见的（一般高级一点的编程语言自带实现）: 线性表 list 哈希表 hash 比较常见的 栈 stack 队列 queue 高级的： 堆 heap 树 tree 图 graphic","categories":[{"name":"软件开发的基础知识","slug":"软件开发的基础知识","permalink":"ityuhui.github.io/categories/软件开发的基础知识/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"ityuhui.github.io/tags/数据结构/"}]},{"title":"从哪里买技术书","slug":"reading-books-from","date":"2015-03-11T12:58:29.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2015/03/11/reading-books-from/","link":"","permalink":"ityuhui.github.io/2015/03/11/reading-books-from/","excerpt":"实体书","text":"实体书 人民邮电出版社及旗下的异步社区，以及图灵社区 机械工业出版社及旗下的华章图书和china-pub 电子工业出版社及旗下的博文视点 清华大学出版社 电子书 safari (O’Relly) kindle 豆瓣阅读 多看","categories":[{"name":"技术方面的思考和总结","slug":"技术方面的思考和总结","permalink":"ityuhui.github.io/categories/技术方面的思考和总结/"}],"tags":[{"name":"书","slug":"书","permalink":"ityuhui.github.io/tags/书/"}]},{"title":"树莓派实现家庭监控","slug":"raspberrypi-home-monitor","date":"2014-10-18T15:22:08.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/10/18/raspberrypi-home-monitor/","link":"","permalink":"ityuhui.github.io/2014/10/18/raspberrypi-home-monitor/","excerpt":"器材树莓派 B版本 摄像头 Z-Star Microelectronics Corp. ZC0301 Webcam 电源 5V2A","text":"器材树莓派 B版本 摄像头 Z-Star Microelectronics Corp. ZC0301 Webcam 电源 5V2A 准备摄像头需要调整，就是旋转摄像头前面的镜头对焦，否则拍出来的照片很模糊。 fswebcam方案安装安装之前要升级一下树莓派系统 12apt-get updateapt-get upgrade 安装fswebcam 1apt-get install fswebcam 使用发命令 1fswebcam -r 640x480 -d /dev/video0 testpictire.jpg 就可以了，再写一个将这个文件发送到邮箱里的脚本，或者scp到自己的VPS上去，或者直接在树莓派上安装httpd或者samba motion 方案安装安装motion 1apt-get install motion 配置修改/etc/motion/motion.conf修改下面三项： 这一项是因为我的摄像头只支持jpeg格式，你可能不需要修改 1v4l2_palette 3 为了能让外部机器访问 1webcam_localhost off 自动保存的照片的地址： 1target_dir 然后启动 1motion -n 使用用浏览器打开ip:8081就可以观看视频了","categories":[{"name":"树莓派","slug":"树莓派","permalink":"ityuhui.github.io/categories/树莓派/"}],"tags":[{"name":"树莓派","slug":"树莓派","permalink":"ityuhui.github.io/tags/树莓派/"}]},{"title":"使用spring boot构建web app","slug":"using-spring-boot-to-build-web-app","date":"2014-05-31T07:30:28.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/05/31/using-spring-boot-to-build-web-app/","link":"","permalink":"ityuhui.github.io/2014/05/31/using-spring-boot-to-build-web-app/","excerpt":"在2014年5月，流行的Java web框架可能只有struts2和springMVC了。 spring是一个非常大的项目组合，几乎涵盖了java web开发领域的各个方面。目前官方推荐的使用spring boot来开发web app。另外，官方的例子都使用了gradle工具来进行build和依赖管理，由于我找不到一个好用的gradle plugin for eclipse, 所以，我仍然使用了maven(m2eclipse)。","text":"在2014年5月，流行的Java web框架可能只有struts2和springMVC了。 spring是一个非常大的项目组合，几乎涵盖了java web开发领域的各个方面。目前官方推荐的使用spring boot来开发web app。另外，官方的例子都使用了gradle工具来进行build和依赖管理，由于我找不到一个好用的gradle plugin for eclipse, 所以，我仍然使用了maven(m2eclipse)。 安装和配置好m2eclipse创建一个空的java项目，当然也可以使用maven创建项目。将项目转为maven项目，注意pom.xml一定要放到项目的根目录下。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.yuhui.webapp&lt;/groupId&gt; &lt;artifactId&gt;YangCheJi&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;YangCheJi&lt;/name&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.0.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;properties&gt; &lt;start-class&gt;hello.Application&lt;/start-class&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;url&gt;http://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;spring-milestone&lt;/id&gt; &lt;url&gt;http://repo.spring.io/libs-milestone&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt;&lt;/project&gt; 创建目录src/main/java/hello src/main/resources/templates 创建文件src/main/java/hello/GreetingController.java 12345678910111213141516package hello; import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam; @Controllerpublic class GreetingController &#123; @RequestMapping(\"/greeting\") public String greeting(@RequestParam(value=\"name\", required=false, defaultValue=\"World\") String name, Model model) &#123; model.addAttribute(\"name\", name); return \"greeting\"; &#125;&#125; src/main/java/hello/Application.java 123456789101112131415package hello; import org.springframework.boot.autoconfigure.EnableAutoConfiguration;import org.springframework.boot.SpringApplication;import org.springframework.context.annotation.ComponentScan; @ComponentScan@EnableAutoConfigurationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; &#125; src/main/resources/templates/greeting.html 12345678910&lt;!DOCTYPE HTML&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;title&gt;Getting Started: Serving Web Content&lt;/title&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;&lt;/head&gt;&lt;body&gt; &lt;p th:text=\"'hi, ' + $&#123;name&#125; + '!'\" /&gt;&lt;/body&gt;&lt;/html&gt; run as maven “spring-boot:run”，访问http://127.0.0.1:8080/greeting生成了一个jar文件，也可以用命令行启动, java -jar XX.jar","categories":[{"name":"Java","slug":"Java","permalink":"ityuhui.github.io/categories/Java/"}],"tags":[{"name":"spring","slug":"spring","permalink":"ityuhui.github.io/tags/spring/"},{"name":"web development","slug":"web-development","permalink":"ityuhui.github.io/tags/web-development/"}]},{"title":"什么是编译器里的前端和后端","slug":"front-backend-for-compiler","date":"2014-02-04T15:07:56.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/02/04/front-backend-for-compiler/","link":"","permalink":"ityuhui.github.io/2014/02/04/front-backend-for-compiler/","excerpt":"","text":"编译器粗略分为词法分析，语法分析，类型检查，中间代码生成，代码优化，目标代码生成，目标代码优化。把中间代码生成及之前阶段划分问编译器的前端，那么后端与前端是独立的。后端只需要一种中间代码表示，可以是三地址代码或四元式等，而这些都与前端生成的方式无关。 按照这个分类，自己动手编写编译器，可以不必从头开始了。使用LLVM，我们可以做一个前端，然后和LLVM后端对接。","categories":[{"name":"编译器","slug":"编译器","permalink":"ityuhui.github.io/categories/编译器/"}],"tags":[{"name":"编译器","slug":"编译器","permalink":"ityuhui.github.io/tags/编译器/"}]},{"title":"如何创建一个自己的git服务器","slug":"create-git-server","date":"2014-01-27T14:24:59.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/01/27/create-git-server/","link":"","permalink":"ityuhui.github.io/2014/01/27/create-git-server/","excerpt":"前提条件客户端：Windows 服务器：Ubuntu","text":"前提条件客户端：Windows 服务器：Ubuntu 安装客户端的安装安装git 生成 idrsa, idrsa.pub 1ssh-keygen -t rsa 服务器的安装和使用安装git 1apt-get install git-core 将客户端的id_rsa.pub里的内容放到.ssh目录下的配置文件里 1cat 客户端的id_rsa_user1.pub &gt;&gt; 服务器的~/.ssh/authorized_keys 建立Git Repository 123mkdir -p /some/dir/project_name.gitcd /some/dir/project_name.gitgit init --bare --shared 客户端的使用有两种方法 1123456git clone git@example.com:/var/cache/git/project_name.gitcd project_namevim test.txtgit add .git commit -m 'add test.txt'git push origin master 21234567mkdir project_namecd project_namegit initgit add .git commit -m 'initial commit'git remote add origin git@example.com:/var/cache/git/project_name.gitgit push origin master 参考文档http://blog.csdn.net/markddi/article/details/8278015","categories":[{"name":"git的使用","slug":"git的使用","permalink":"ityuhui.github.io/categories/git的使用/"}],"tags":[{"name":"git","slug":"git","permalink":"ityuhui.github.io/tags/git/"}]},{"title":"source and export","slug":"source-and-export","date":"2014-01-27T14:19:15.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/01/27/source-and-export/","link":"","permalink":"ityuhui.github.io/2014/01/27/source-and-export/","excerpt":"","text":"export让子进程获得父进程的变量，没有其他的解释 source让source的脚本在当前的shell环境下运行，不再fork一个新shell运行，没有其他的解释","categories":[{"name":"Linux","slug":"Linux","permalink":"ityuhui.github.io/categories/Linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"ityuhui.github.io/tags/linux/"},{"name":"shell","slug":"shell","permalink":"ityuhui.github.io/tags/shell/"},{"name":"bash","slug":"bash","permalink":"ityuhui.github.io/tags/bash/"}]},{"title":"在x86机器的屏幕上显示的三种方法","slug":"display-on-x86","date":"2014-01-25T14:55:33.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2014/01/25/display-on-x86/","link":"","permalink":"ityuhui.github.io/2014/01/25/display-on-x86/","excerpt":"在实现x86操作系统的时候，肯定要在屏幕上显示字符、图形和图像，我个人总结，有三种在屏幕上显示的方法。","text":"在实现x86操作系统的时候，肯定要在屏幕上显示字符、图形和图像，我个人总结，有三种在屏幕上显示的方法。 1. 调用BIOS中断将数据写入内存，将内存指针存入CPU寄存器，调用中断。实模式下使用。相比较第二种方法的好处是，BIOS自带英文字库，编程简单。使用汇编实现。最终BIOS肯定是将数据发送到了显卡上的显存（帧缓存）上。 2. 向显存里直接写数据也就是所谓的“直接写屏”。 实模式和保护模式下都可以使用，但是只有640KB。这640KB是和内存统一编址的，所以实际上这段物理内存被屏蔽了。通常用C语言实现。超过640KB的部分需要使用第三种方法。最终写到显卡的显存上。 3. 向显卡外设端口写指令和数据这也是平时我们在使用电脑时的方法，当然，指令和数据是由应用程序发出的。保护模式下使用。最终由GPU处理后写到显存上。","categories":[{"name":"操作系统开发","slug":"操作系统开发","permalink":"ityuhui.github.io/categories/操作系统开发/"}],"tags":[{"name":"操作系统开发","slug":"操作系统开发","permalink":"ityuhui.github.io/tags/操作系统开发/"}]},{"title":"对桌面GUI库的思考","slug":"thinking-about-desktop-gui","date":"2013-09-11T08:47:49.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2013/09/11/thinking-about-desktop-gui/","link":"","permalink":"ityuhui.github.io/2013/09/11/thinking-about-desktop-gui/","excerpt":"QT先说QT吧，不管怎么说我也做过两年左右的开发，直到现在，我也认为是最好的C++跨平台GUI库，消息和槽的机制，比Win32/MFC的消息机制要简单很多。","text":"QT先说QT吧，不管怎么说我也做过两年左右的开发，直到现在，我也认为是最好的C++跨平台GUI库，消息和槽的机制，比Win32/MFC的消息机制要简单很多。 GTK再说GTK，*nix系的C图形库，几乎在Linux桌面一统江湖。 SWT然后说SWT，eclipse的GUI库，外观超过jdk自身的桌面GUI库swing，配置eclipse，可以写出很漂亮的应用，还可以跨平台。不过目前已经无人采用了。 MFC接下来就是MFC/Win32了吧，不知道这个东西现在用的人还有多少，不过写高性能的Windows桌面程序还就得靠他。另外，自己写图形库的话，底层肯定也绕不过Win32。 .net再就是.net的桌面应用，写起来容易，也是微软力推的。","categories":[{"name":"技术方面的思考和总结","slug":"技术方面的思考和总结","permalink":"ityuhui.github.io/categories/技术方面的思考和总结/"}],"tags":[{"name":"思考","slug":"思考","permalink":"ityuhui.github.io/tags/思考/"},{"name":"GUI","slug":"GUI","permalink":"ityuhui.github.io/tags/GUI/"}]},{"title":"如何学习","slug":"how-to-learn-tech","date":"2013-08-24T13:34:37.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2013/08/24/how-to-learn-tech/","link":"","permalink":"ityuhui.github.io/2013/08/24/how-to-learn-tech/","excerpt":"首先，肯定还要看书，书是前人总结的经验，相比较网络上的博文，书的内容，比较系统，也比较精致。最近一两年，技术书的价格涨得很厉害，但是我觉得，好书还是对得起它的标价。与其从网络上浏览和搜集，不如看书，可以节省时间。技术书，至少要看两遍，第一遍，阅读，第二遍，完成书上所有的例子，提供完整源代码的书，是值得买的。","text":"首先，肯定还要看书，书是前人总结的经验，相比较网络上的博文，书的内容，比较系统，也比较精致。最近一两年，技术书的价格涨得很厉害，但是我觉得，好书还是对得起它的标价。与其从网络上浏览和搜集，不如看书，可以节省时间。技术书，至少要看两遍，第一遍，阅读，第二遍，完成书上所有的例子，提供完整源代码的书，是值得买的。 其次，看书绝对不是掌握技术的最好方法，最好的方法，是在工作中学习，由于有考核的压力，工作中遇到的新技术是一定要掌握的，而且是一定要形成生产力的。 最后，我觉得也是最重要的，是在业余时间做自己设计的项目。这种项目出于自己的兴趣和需求所以会比较有动力。就我个人的经验，在大公司里，你很难在工作中遇到自己想要做的项目，总是在做一些公司项目里修补和改善，无法对自己的技术能力有较快和较大的提升。但是这样做会挤占本来就不多的业余时间，对于有家的程序员来说，需要在家庭生活和技术提高上找到一个平衡点。","categories":[{"name":"技术方面的思考和总结","slug":"技术方面的思考和总结","permalink":"ityuhui.github.io/categories/技术方面的思考和总结/"}],"tags":[{"name":"学习","slug":"学习","permalink":"ityuhui.github.io/tags/学习/"},{"name":"思考","slug":"思考","permalink":"ityuhui.github.io/tags/思考/"}]},{"title":"如何将python脚本转换成在Windows系统的可执行程序exe","slug":"convert-python-app-to-exe","date":"2013-08-24T09:11:00.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2013/08/24/convert-python-app-to-exe/","link":"","permalink":"ityuhui.github.io/2013/08/24/convert-python-app-to-exe/","excerpt":"截止到2012年12月，将python脚本转换成exe的最好的工具是pyinstaller","text":"截止到2012年12月，将python脚本转换成exe的最好的工具是pyinstaller 1下载python，可以下载2系列的，也可以下载3系列的，安装。 下载pywin32（请使用搜索引擎，官方网站在sourceforge上）,下载对应于python的版本号，以及电脑CPU架构（32位或64位）的版本，安装。 2如果pywin32安装不成功，可以卸载掉python和pywin32，然后下载另外一个版本号的版本 3下载pyinstaller（请使用搜索引擎，官方网站在sourceforge上），解压缩到某个目录，例如/to/your/path/pyinstaller-2.0 4确保python脚本，例如 test.py可以正常执行，无错误。 5将test.py放到/to/your/path/pyinstaller-2.0目录下 6在/to/your/path/pyinstaller-2.0目录下执行python pyinstaller.py –-onefile test.py （注意onefile前面有两个-符号） 7test.exe将生成在/to/your/path/pyinstaller-2.0/test/dist/目录下","categories":[{"name":"Python","slug":"Python","permalink":"ityuhui.github.io/categories/Python/"}],"tags":[{"name":"Python","slug":"Python","permalink":"ityuhui.github.io/tags/Python/"},{"name":"pyinstaller","slug":"pyinstaller","permalink":"ityuhui.github.io/tags/pyinstaller/"}]},{"title":"x86系统引导","slug":"boot-x86","date":"2010-04-29T12:08:00.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2010/04/29/boot-x86/","link":"","permalink":"ityuhui.github.io/2010/04/29/boot-x86/","excerpt":"电脑加电后，BIOS里的程序先运行，装入硬盘的第一个扇区（512B），这里就是MBR，包括硬盘分区表和引导程序。 引导程序引导到逻辑盘里的操作系统引导程序。也可以把操作系统引导程序（例如GRUB）放到MBR里，省去一个步骤。这就是为什么GRUB可以装在MBR里，也可以装载到逻辑分区里。","text":"电脑加电后，BIOS里的程序先运行，装入硬盘的第一个扇区（512B），这里就是MBR，包括硬盘分区表和引导程序。 引导程序引导到逻辑盘里的操作系统引导程序。也可以把操作系统引导程序（例如GRUB）放到MBR里，省去一个步骤。这就是为什么GRUB可以装在MBR里，也可以装载到逻辑分区里。 GRUB负责引导Linux内核源代码arch/i386/boot/里的汇编代码写的启动程序，这个启动程序再启动内核。 BIOS-&gt;GRUB-&gt;初始化程序没有GRUB的话，BIOS-&gt;初始化程序 bootsect还是16位实模式，在Setup中进行保护模式。","categories":[{"name":"操作系统开发","slug":"操作系统开发","permalink":"ityuhui.github.io/categories/操作系统开发/"}],"tags":[{"name":"操作系统开发","slug":"操作系统开发","permalink":"ityuhui.github.io/tags/操作系统开发/"}]},{"title":"C语言二级指针和二维数组","slug":"c-array-2-lvl-pointer","date":"2010-04-21T15:00:00.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2010/04/21/c-array-2-lvl-pointer/","link":"","permalink":"ityuhui.github.io/2010/04/21/c-array-2-lvl-pointer/","excerpt":"Examples:123 int c[1][2]=&#123;2,3&#125;; int (*b)[2]; b=c;","text":"Examples:123 int c[1][2]=&#123;2,3&#125;; int (*b)[2]; b=c; 总结1**b 和 1b[][] 是不同的。但是 1(*b)[] 和 1b[][] 是相通的。 理解理解这些，首先，要说，这是一个什么，然后说，什么的什么 1*b[2] b是一个一维数组，数组的长度是2，每个元素是一个指针 1(*b)[2] b是一个指针，指向一个数组，这个数组的长度是2 1c[1][2] c是一个二维数组，也可以说是一个指针，指向一个长度为2的数组 1**d d是一个指针的指针，指向的内容也是一个指针","categories":[{"name":"C语言","slug":"C语言","permalink":"ityuhui.github.io/categories/C语言/"}],"tags":[{"name":"c","slug":"c","permalink":"ityuhui.github.io/tags/c/"},{"name":"二级指针","slug":"二级指针","permalink":"ityuhui.github.io/tags/二级指针/"},{"name":"二维数组","slug":"二维数组","permalink":"ityuhui.github.io/tags/二维数组/"}]},{"title":"VTK的小总结","slug":"about-vtk","date":"2010-04-10T11:05:00.000Z","updated":"2020-06-13T12:48:12.894Z","comments":true,"path":"2010/04/10/about-vtk/","link":"","permalink":"ityuhui.github.io/2010/04/10/about-vtk/","excerpt":"","text":"vtk是一个开源的可视化工具包 用于计算机图形学，图像处理，医学图像处理等研究和开发领域 是OpenGL的上层封装库，C++编写 支持多语言二次开发，可以和MFC集成","categories":[{"name":"VTK","slug":"VTK","permalink":"ityuhui.github.io/categories/VTK/"}],"tags":[{"name":"vtk","slug":"vtk","permalink":"ityuhui.github.io/tags/vtk/"}]},{"title":"C语言字符编码的一点总结","slug":"computer-encoding-summary","date":"2010-04-10T11:03:00.000Z","updated":"2020-06-13T12:48:12.910Z","comments":true,"path":"2010/04/10/computer-encoding-summary/","link":"","permalink":"ityuhui.github.io/2010/04/10/computer-encoding-summary/","excerpt":"wchar_t 其实只是对应于UTF-16的，也就是UCS2，但是编译器一般实现为4个字节","text":"wchar_t 其实只是对应于UTF-16的，也就是UCS2，但是编译器一般实现为4个字节 Linux下广泛使用UFT-8，UTF-8并不是宽字符，而是多字符 Unicode并不等于宽字符，UTF-16才是宽字符 wout输出要先设置locale，是因为要进行宽字符到多字符的转换，多字符的现实，需要指定活动代码页","categories":[{"name":"软件开发的基础知识","slug":"软件开发的基础知识","permalink":"ityuhui.github.io/categories/软件开发的基础知识/"}],"tags":[{"name":"计算机编码","slug":"计算机编码","permalink":"ityuhui.github.io/tags/计算机编码/"},{"name":"utf","slug":"utf","permalink":"ityuhui.github.io/tags/utf/"},{"name":"宽字符","slug":"宽字符","permalink":"ityuhui.github.io/tags/宽字符/"}]}]}